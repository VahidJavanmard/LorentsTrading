{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from indicators import *\n",
    "\n",
    "import os\n",
    "\n",
    "def install_requirements():\n",
    "    os.system('pip install -r requirements.txt')\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    # install_requirements()\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     multiprocessing.freeze_support()\n",
    "#     BeautyChart.main()\n",
    "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "#تنظیمات api , تلگرام"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIURL=\"https://open-api.bingx.com\"\n",
    "# APIKEY=\"yhMMfr0fbRsinaHaPnhesLhhaE5nur7D3W034jCpyURP1CFnI1T0Yjxmt77TpdGcCD3wnTDI5LXoVL0yYF9w\"\n",
    "# SECRETKEY=\"HMaxI039IQpRkKPIaxI6PUSI0I11pDDId6gEzWXO2yDARgp1ZgDvSB0GQVvB92OZ9sn9jNbp4I1SoRIrw\"\n",
    "APIKEY=\"oM0qKrqgmibx0a2VHVBwn4oBuWLLdqQBdlQ73kvLnHIqlbzgvewRrt2kk1YbUURcP7K0e1izVtaqjyehrg\"\n",
    "SECRETKEY=\"usj3lCWX2NKN17PqyE7HB8G3Jb0D4NpHBzGyKy3FUphKjJF6bx2wTNiB8I1jWFyun6pB3JGoAFhIzIQDHhwg\"\n",
    "telegram_bot_token='142615795:AAGdGxG0GpxEi-iu23sKAuVctdLqQ5hgKB4'\n",
    "telegram_channel_id='@tradinghistorytest'\n",
    "# telegram_channel_id=70074075\n",
    "# bot=Bot(token=telegram_bot_token)\n",
    "bot=telebot.TeleBot(telegram_bot_token)\n",
    "BotId=\"My PC\"\n",
    "cycle=[]\n",
    "cycle_status=False\n",
    "csv=False\n",
    "signalPrice=0\n",
    "lastSignalAction=3\n",
    "lastSignalExcell=3\n",
    "actionStatus=\"\"\n",
    "profit=0.00\n",
    "sendMessage=False\n",
    "closedMethod=\"\"\n",
    "#تعداد کندل برای محاسبه درصد تغییر\n",
    "shiftedNumber=1\n",
    "#درصد تغییر برای قرار داد ن  در کلاس no Action\n",
    "expectedChange=0\n",
    "#درصد دقت برای سیگنال\n",
    "expectedAccuracy=0.30\n",
    "\n",
    "shiftedNumber_range = range(1, 10)\n",
    "expectedChange_range = np.arange(0.1, 0.5, 0.1)\n",
    "\n",
    "expectedCombineModel=0.40\n",
    "expectedLstmModel=0.4\n",
    "expectedSvmModel=0.40\n",
    "\n",
    "trainTimeStamp=datetime.now()\n",
    "\n",
    "#بارگذاری داده ها\n",
    "# symbol=\"BTC-USDT\"\n",
    "symbol=\"BTC-USDT\"\n",
    "# symbol=\"FTM-USDT\"\n",
    "\n",
    "indicatorSource='close'\n",
    "timeframe=\"1d\"\n",
    "limit=1000\n",
    "percentTest=0.05\n",
    "n_Candle_Train=10\n",
    "\n",
    "lstm_model=None\n",
    "svm_model=None\n",
    "combine_model=None\n",
    "accuracy=-1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#indicator Sell Buy Zone\n",
    "\n",
    "rsi_overbought = 70\n",
    "rsi_oversold = 30\n",
    "macd_threshold = 0\n",
    "adx_threshold = 25\n",
    "cci_overbought = 100\n",
    "cci_oversold = -100\n",
    "stochastic_high = 80\n",
    "stochastic_low = 20\n",
    "\n",
    "\n",
    "scaler= StandardScaler()\n",
    "\n",
    "# accuracy=None\n",
    "# تنظیم زمان به قبرس\n",
    "cyprus_timezone=pytz.timezone('Asia/Nicosia')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "68458.31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def DrawChartNew():\n",
    "    if __name__ == '__main__':\n",
    "        chart = Chart(toolbox=True)\n",
    "            \n",
    "            # Columns: time | open | high | low | close | volume \n",
    "            # df = pd.read_csv('ohlcv.csv')\n",
    "        # df=data\n",
    "        df = pd.read_csv('BTC-USDT4h2024-05-24 08-00-00.csv')\n",
    "        df['date'] = pd.to_datetime(df['timestamp'])  # تبدیل ستون timestamp به فرمت datetime\n",
    "            # df['date'] = df['timestamp'].map(mdates.date2num)\n",
    "            # df.to_csv(\"test.csv\")\n",
    "        chart.set(df, render_drawings=True)\n",
    "        for index in  df.itertuples(index=True, name='Pandas'):\n",
    "            i = index\n",
    "            if(i.marker=='B'):\n",
    "                chart.marker(i.date,'inside','arrow_up','green',i.close)\n",
    "            elif (i.marker=='C'):\n",
    "                chart.marker( i.date,'inside','circle','white',i.close)\n",
    "            elif (i.marker=='CB'):\n",
    "                chart.marker(i.date,'inside','arrow_up','green',i.close)\n",
    "            elif (i.marker=='CB'):\n",
    "                chart.marker(i.date,'inside','arrow_down','red',i.close)\n",
    "            elif (i.marker=='S'):\n",
    "                chart.marker(i.date,'inside','arrow_down','red',i.close)\n",
    "\n",
    "            \n",
    "        chart.watermark('BTC-USDT 1D', color='rgba(180, 180, 240, 0.7)')\n",
    "        chart.crosshair(mode='normal', vert_color='#FFFFFF', vert_style='dotted',\n",
    "                            horz_color='#FFFFFF', horz_style='dotted')\n",
    "\n",
    "        chart.show(block=True)\n",
    "    \n",
    "\n",
    "# DrawChartNew()\n",
    "#import n*timefrime\n",
    "def add_time(current_time, time_string):\n",
    "    unit = time_string[-1]\n",
    "    value = int(time_string[:-1])\n",
    "    \n",
    "    if unit == 'm':  # minutes\n",
    "        delta = timedelta(minutes=value)\n",
    "    elif unit == 'h':  # hours\n",
    "        delta = timedelta(hours=value)\n",
    "    elif unit == 's':  # seconds\n",
    "        delta = timedelta(seconds=value)\n",
    "    elif unit == 'd':  # days\n",
    "        delta = timedelta(days=value)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported time unit. Use 's' for seconds, 'm' for minutes, 'h' for hours, or 'd' for days.\")\n",
    "    \n",
    "    return current_time + delta\n",
    "\n",
    "def add_time_multiple(current_time, time_string, count):\n",
    "    for _ in range(count):\n",
    "        current_time = add_time(current_time, time_string)\n",
    "    return current_time\n",
    "\n",
    "\n",
    "def get_cyprus_time():\n",
    "    utc_time=datetime.now(timezone.utc)\n",
    "    # # utc_time=datetime.now(utc)\n",
    "    utc_time=utc_time.replace(tzinfo=pytz.utc)\n",
    "    local_time=utc_time.astimezone(cyprus_timezone)\n",
    "    return local_time\n",
    "\n",
    "def get_sign(api_secret,payload):\n",
    "    signature=hmac.new(api_secret.encode(\"utf-8\"),payload.encode(\"utf-8\"),hashlib.sha256).hexdigest()\n",
    "    return signature\n",
    "\n",
    "def parseParam(paramsMap):\n",
    "    sortedKeys=sorted(paramsMap)\n",
    "    paramsStr=\"&\".join([f\"{key}={paramsMap[key]}\" for key in sortedKeys])\n",
    "    return paramsStr + \"&timestamp\"+ str(int(time.time()*1000))\n",
    "\n",
    "def send_request(method, path, url_params, payload=\"\"):\n",
    "    url =f\"{APIURL}{path}?{url_params}&signature={get_sign(SECRETKEY, url_params)}\"\n",
    "    headers = {'X-BX-APIKEY': APIKEY}\n",
    "    response = requests.request(method, url, headers-headers, data-payload)\n",
    "    return response.json()\n",
    "\n",
    "def curentdata():\n",
    "    exchange=ccxt.bingx()\n",
    "    ticker = exchange.fetch_ticker(symbol)\n",
    "    lastprice= ticker['last']\n",
    "    print(\"lastprice\",lastprice)\n",
    "    return lastprice\n",
    "\n",
    "def getLastPrice(data):\n",
    "    return curentdata()\n",
    "\n",
    "\n",
    "def add_indicators(df):\n",
    "    global data\n",
    "    # محاسبه 20 اندیکاتور فنی\n",
    "    # df['rsi'] = ta.momentum.RSIIndicator(df[indicatorSource]).rsi()\n",
    "    df['macd'] = ta.trend.MACD(df[indicatorSource]).macd()\n",
    "    # df['macd_diff'] = ta.trend.MACD(df[indicatorSource]).macd_diff()\n",
    "    # df['ema'] = ta.trend.EMAIndicator(df[indicatorSource]).ema_indicator()\n",
    "    # df['bollinger_mavg'] = ta.volatility.BollingerBands(df[indicatorSource]).bollinger_mavg()\n",
    "    # df['bollinger_hband'] = ta.volatility.BollingerBands(df[indicatorSource]).bollinger_hband()\n",
    "    # df['bollinger_lband'] = ta.volatility.BollingerBands(df[indicatorSource]).bollinger_lband()\n",
    "    # df['stochastic_oscillator'] = ta.momentum.StochasticOscillator(df['high'], df['low'], df['close']).stoch()\n",
    "    df['stochastic'] = ta.momentum.StochasticOscillator(df['high'], df['low'], df['close']).stoch()\n",
    "    # df['cci'] = ta.trend.CCIIndicator(df['high'], df['low'], df['close']).cci()\n",
    "    # df['adx'] = ta.trend.ADXIndicator(df['high'], df['low'], df['close']).adx()\n",
    "    # df['williams_r'] = ta.momentum.WilliamsRIndicator(df['high'], df['low'], df['close']).williams_r()\n",
    "    # df['roc'] = ta.momentum.ROCIndicator(df['close']).roc()\n",
    "    # df['atr'] = ta.volatility.AverageTrueRange(df['high'], df['low'], df['close']).average_true_range()\n",
    "    # df['mfi'] = ta.volume.MFIIndicator(df['high'], df['low'], df['close'], df['volume']).money_flow_index()\n",
    "    # df['obv'] = ta.volume.OnBalanceVolumeIndicator(df['close'], df['volume']).on_balance_volume()\n",
    "    # df['force_index'] = ta.volume.ForceIndexIndicator(df['close'], df['volume']).force_index()\n",
    "    # df['tsi'] = ta.momentum.TSIIndicator(df[indicatorSource]).tsi()\n",
    "    # df['ultimate_oscillator'] = ta.momentum.UltimateOscillator(df['high'], df['low'], df['close']).ultimate_oscillator()\n",
    "    # df['kama'] = ta.momentum.KAMAIndicator(df[indicatorSource]).kama()\n",
    "    # df['dpo'] = ta.trend.DPOIndicator(df[indicatorSource]).dpo()\n",
    "    # df=calculate_linear_regression_channel(df)\n",
    "    \n",
    "    df = dropNaFix(df)\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "def dropNaFix(df):\n",
    "    last_10_rows = df.tail(shiftedNumber)\n",
    "    # اعمال dropna بر روی سایر سطرها\n",
    "    df_cleaned = df.iloc[:-shiftedNumber].dropna()\n",
    "    \n",
    "    # بازگرداندن ده سطر آخر به DataFrame\n",
    "    df_cleaned = pd.concat([df_cleaned, last_10_rows])\n",
    "    # تنظیم ایندکس‌ها\n",
    "    df_cleaned = df_cleaned.reset_index(drop=True)\n",
    "    # df = df.dropna()\n",
    "    return df_cleaned\n",
    "     #توابع مربوط به محاسبات\n",
    "\n",
    "def drawChart():\n",
    "\n",
    "#رسم نمودار\n",
    "    plt.figure(figsize=(15,10))\n",
    "    #نمودار RSI\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(data['rsi'],label='RSI')\n",
    "    plt.axhline(50,color='grey',linestyle='--')\n",
    "    plt.title('Relative Stregth Index (Rsi)')\n",
    "    plt.legend()\n",
    "\n",
    "    #نمودار ADX\n",
    "    plt.subplot(4,1,2)\n",
    "    plt.plot(data['adx'],label='ADX')\n",
    "    plt.axhline(25,color='grey',linestyle='--')\n",
    "    plt.title('Average Directional Index (ADX)')\n",
    "    plt.legend()\n",
    "\n",
    "    #نمودار DI+ و DI-\n",
    "    # plt.subplot(4,1,3)\n",
    "    # plt.plot(data['plus_di'],label='DI+')\n",
    "    # plt.plot(data['minus_di'],label='DI-')\n",
    "    # plt.title('Directional Movement Indicators')\n",
    "    # plt.legend()\n",
    "\n",
    "    #نمودار سیگنال های خرید و فروش\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(data['close'],label='Close Price')\n",
    "    buy_signals=data[data['trade_signal']=='buy']\n",
    "    sell_signals=data[data['trade_signal']=='sell']\n",
    "    plt.scatter(buy_signals.index,buy_signals['close'],marker='^',color='g',label='Buy Signal',alpha=1)\n",
    "    plt.scatter(sell_signals.index,sell_signals['close'],marker='v',color='r',label='Sell Signal',alpha=1)\n",
    "    plt.title('Buy/Sell Signals')\n",
    "    plt.legend()\n",
    "\n",
    "    #نمایش نمودار ها\n",
    "    plt.tight_layout()\n",
    "    # plt.draw()\n",
    "    # plt.show(block=False)\n",
    "    # plt.ion()\n",
    "    # plt.ion()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def cosine_distance(x1, x2):\n",
    "    return cosine(x1, x2)\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    return np.sqrt(np.sum((np.array(x) - np.array(y)) ** 2))\n",
    "\n",
    "\n",
    "def lorentzian_distance(x, y):\n",
    "    return np.sum(np.log1p(np.abs(x - y) ** 2))\n",
    "\n",
    "def calculate_buy_sell_signals(data,delay_period=1):\n",
    "\n",
    "    #محاسبه شاخص های adx ,rsi\n",
    "    data['adx']=ta.trend.adx(data['high'],data['low'],data['close'],window=14,fillna=True)\n",
    "    data['rsi']=ta.momentum.rsi(data['close'],window=14,fillna=True)\n",
    "\n",
    "    #مقدار دهی اولیه متغییر ها\n",
    "    cycle_open=False\n",
    "    cycle_type=None\n",
    "    last_cycle_type=None\n",
    "    data['trade_signal']=None\n",
    "    data['cycle_status']=None\n",
    "    potential_signal_time=None\n",
    "    potential_signal_type=None\n",
    "\n",
    "    #(crossover) برای بررسی عبور DI- , DI+ ذخیره مقادیر قبلی\n",
    "    previous_plus_di=data['plus_di'].shift(1)\n",
    "    previous_plus_di=previous_plus_di.dropna()\n",
    "    previous_minus_di=data['minus_di'].shift(1)\n",
    "    previous_minus_di=previous_minus_di.dropna()\n",
    "\n",
    "    # if cycle[-1]=\"closed\"\n",
    "    for i in range(1,len(data)):\n",
    "        current_time=data.loc[i,'timestamp']\n",
    "\n",
    "        #بررسی استمرار شرایط سیگنال پس ار گذشت تاخیر\n",
    "        if potential_signal_time and (current_time- potential_signal_time).total_seconds()>=delay_period*60:\n",
    "            if potential_signal_type =='buy' and (data.loc[i,'plus_di']<data.loc[i,'minus_di']):\n",
    "                cycle_open=True\n",
    "                cycle_type='buy'\n",
    "                data.loc[i,'trade_signal']='buy'\n",
    "                data.loc[i,'cycle_status']='open'\n",
    "            elif potential_signal_type=='sell' and (data.loc[i,'minus_di']>data.loc[i,'plus_di']):\n",
    "                cycle_open=True\n",
    "                cycle_type='sell'\n",
    "                data.loc[i,'trade_signal']='sell'\n",
    "                data.loc[i,'cycle_status']='open'\n",
    "            potential_signal_time=None\n",
    "\n",
    "            #بررسی شرایط سیگنال بدون تاخیر\n",
    "            if not cycle_open:\n",
    "                if(data.loc[i,'plus_di']>data.loc[i,'minus_di']) and   (data.loc[i,'ADX'] >25) and (data.loc[i,'RSI']<50):\n",
    "                    potential_signal_time=current_time\n",
    "                    potential_signal_type='buy'\n",
    "                elif (data.loc[i,'minus_di']<data.loc[i,'plus_di']) and   (data.loc[i,'ADX'] <25) and (data.loc[i,'RSI']<50):\n",
    "                    potential_signal_time=current_time\n",
    "                    potential_signal_type='sell'\n",
    "\n",
    "            #برای برستن سیکل cross over بررسی عبور\n",
    "            if cycle_open:\n",
    "                if cycle_type=='buy' and (data.loc[i,'minus_di']<data.loc[i,'plus_di']) and (previous_plus_di[i]<previous_minus_di[i]):\n",
    "                    cycle_open=False\n",
    "                    last_cycle_type='buy'\n",
    "                    data.loc[i,'trade_signal']='sell'\n",
    "                    data.loc[i,'cycle_status']='closed'\n",
    "                elif cycle_type=='sell' and (data.loc[i,'plus_du']<data.loc[i,'minus_di']) and (previous_minus_di[i] < previous_plus_di[i]):\n",
    "                    cycle_open=False\n",
    "                    last_cycle_type='sell'\n",
    "                    data.loc[i,'trade_signal']='buy'\n",
    "                    data.loc[i,'cycle_status']='closed'\n",
    "    return data\n",
    "def CloseSignalWithIndicators(data, delay_period=1,CheckCycle=True,signalAction=lastSignalAction):\n",
    "    # محاسبه شاخص های adx, rsi, mfi\n",
    "    data['adx'] = ta.trend.adx(data['high'], data['low'], data['close'], window=14, fillna=True)\n",
    "    data['rsi'] = ta.momentum.rsi(data['close'], window=14, fillna=True)\n",
    "    data['mfi'] = ta.volume.money_flow_index(data['high'], data['low'], data['close'], data['volume'], window=14, fillna=True)\n",
    "\n",
    "    # مقداردهی اولیه متغیرها\n",
    "    # cycle_open = False\n",
    "    # cycle_type = None\n",
    "    # last_cycle_type = None\n",
    "    # potential_signal_time = None\n",
    "    # potential_signal_type = None\n",
    "\n",
    "    # # اضافه کردن ستون های trade_signal و cycle_status\n",
    "    # data['trade_signal'] = None\n",
    "    # data['cycle_status'] = None\n",
    "\n",
    "    # # ذخیره مقادیر قبلی MFI\n",
    "    # previous_mfi = data['mfi'].shift(1)\n",
    "    # if cycle_status==False:\n",
    "    # # حلقه اصلی برای بررسی سیگنال‌ها\n",
    "    #     for i in range(1, len(data)):\n",
    "    #         currentMfi = data.loc[i, 'mfi']\n",
    "    #         current_time = data.loc[i, 'timestamp']\n",
    "    #         # بررسی استمرار شرایط سیگنال پس از گذشت تأخیر\n",
    "    #         if potential_signal_time and (current_time - potential_signal_time).total_seconds() >= delay_period * 60:\n",
    "    #             if potential_signal_type == 'buy' and currentMfi > 20:\n",
    "    #                 cycle_open = True\n",
    "    #                 cycle_type = 'buy'\n",
    "    #                 data.loc[i, 'trade_signal'] = 'buy'\n",
    "    #                 data.loc[i, 'cycle_status'] = 'open'\n",
    "    #                 # cycle.append('open')\n",
    "    #                 print(i)\n",
    "    #             elif potential_signal_type == 'sell' and currentMfi < 80:\n",
    "    #                 cycle_open = True\n",
    "    #                 cycle_type = 'sell'\n",
    "    #                 data.loc[i, 'trade_signal'] = 'sell'\n",
    "    #                 data.loc[i, 'cycle_status'] = 'open'\n",
    "    #                 cycle.append('open')\n",
    "    #             potential_signal_time = None\n",
    "\n",
    "    #         # بررسی شرایط سیگنال بدون تأخیر\n",
    "    #         if not cycle_status:\n",
    "    #             if currentMfi < 20 and data.loc[i, 'adx'] > 25 and data.loc[i, 'rsi'] < 50:\n",
    "    #                 potential_signal_time = current_time\n",
    "    #                 potential_signal_type = 'buy'\n",
    "    #             elif currentMfi > 80 and data.loc[i, 'adx'] > 25 and data.loc[i, 'rsi'] > 50:\n",
    "    #                 potential_signal_time = current_time\n",
    "    #                 potential_signal_type = 'sell'\n",
    "    # currentMfi = data.loc[-1, 'mfi']\n",
    "    currentMfi = data['mfi'].iloc[-1]\n",
    "\n",
    "    # return False\n",
    "    #previous_mfi = data.loc[-2, 'mfi']\n",
    "    #         # بررسی عبور برای بستن سیکل\n",
    "\n",
    "    if CheckCycle==False or cycle_status:\n",
    "        if signalAction == 1 and currentMfi > 80 :\n",
    "            print(f\"closed buy :{currentMfi}\")\n",
    "            return True\n",
    "        elif signalAction == 0 and currentMfi < 20 :\n",
    "            print(f\"closed sell: {currentMfi}\")\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "    # return True\n",
    "\n",
    "def OpenSignalWithIndicators(data, delay_period=1,CheckCycle=True,signalAction=lastSignalAction):\n",
    "    # محاسبه شاخص های adx, rsi, mfi\n",
    "    data['adx'] = ta.trend.adx(data['high'], data['low'], data['close'], window=14, fillna=True)\n",
    "    data['rsi'] = ta.momentum.rsi(data['close'], window=14, fillna=True)\n",
    "    data['mfi'] = ta.volume.money_flow_index(data['high'], data['low'], data['close'], data['volume'], window=14, fillna=True)\n",
    "\n",
    "    # مقداردهی اولیه متغیرها\n",
    "    # cycle_open = False\n",
    "    # cycle_type = None\n",
    "    # last_cycle_type = None\n",
    "    # potential_signal_time = None\n",
    "    # potential_signal_type = None\n",
    "\n",
    "    # # اضافه کردن ستون های trade_signal و cycle_status\n",
    "    # data['trade_signal'] = None\n",
    "    # data['cycle_status'] = None\n",
    "\n",
    "    # # ذخیره مقادیر قبلی MFI\n",
    "    # previous_mfi = data['mfi'].shift(1)\n",
    "    # if cycle_status==False:\n",
    "    # # حلقه اصلی برای بررسی سیگنال‌ها\n",
    "    #     for i in range(1, len(data)):\n",
    "    #         currentMfi = data.loc[i, 'mfi']\n",
    "    #         current_time = data.loc[i, 'timestamp']\n",
    "    #         # بررسی استمرار شرایط سیگنال پس از گذشت تأخیر\n",
    "    #         if potential_signal_time and (current_time - potential_signal_time).total_seconds() >= delay_period * 60:\n",
    "    #             if potential_signal_type == 'buy' and currentMfi > 20:\n",
    "    #                 cycle_open = True\n",
    "    #                 cycle_type = 'buy'\n",
    "    #                 data.loc[i, 'trade_signal'] = 'buy'\n",
    "    #                 data.loc[i, 'cycle_status'] = 'open'\n",
    "    #                 # cycle.append('open')\n",
    "    #                 print(i)\n",
    "    #             elif potential_signal_type == 'sell' and currentMfi < 80:\n",
    "    #                 cycle_open = True\n",
    "    #                 cycle_type = 'sell'\n",
    "    #                 data.loc[i, 'trade_signal'] = 'sell'\n",
    "    #                 data.loc[i, 'cycle_status'] = 'open'\n",
    "    #                 cycle.append('open')\n",
    "    #             potential_signal_time = None\n",
    "\n",
    "    #         # بررسی شرایط سیگنال بدون تأخیر\n",
    "    #         if not cycle_status:\n",
    "    #             if currentMfi < 20 and data.loc[i, 'adx'] > 25 and data.loc[i, 'rsi'] < 50:\n",
    "    #                 potential_signal_time = current_time\n",
    "    #                 potential_signal_type = 'buy'\n",
    "    #             elif currentMfi > 80 and data.loc[i, 'adx'] > 25 and data.loc[i, 'rsi'] > 50:\n",
    "    #                 potential_signal_time = current_time\n",
    "    #                 potential_signal_type = 'sell'\n",
    "    # currentMfi = data.loc[-1, 'mfi']\n",
    "    currentMfi = data['mfi'].iloc[-1]\n",
    "    print(f\"Current MFi {currentMfi}\")\n",
    "\n",
    "    # return False\n",
    "    #previous_mfi = data.loc[-2, 'mfi']\n",
    "    #         # بررسی عبور برای بستن سیکل\n",
    "\n",
    "    if CheckCycle==False or cycle_status:\n",
    "        if signalAction == 0 and currentMfi > 80 :\n",
    "            print(f\"Open Sell :{currentMfi}\")\n",
    "            return True\n",
    "        elif signalAction == 1 and currentMfi < 20 :\n",
    "            print(f\"Open buy: {currentMfi}\")\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "    # return True\n",
    "\n",
    "def calculate_buy_sell_signalsSuperTrend(data, delay_period=1):\n",
    "    # محاسبه شاخص های adx, rsi, mfi و supertrend\n",
    "    data['adx'] = ta.trend.adx(data['high'], data['low'], data['close'], window=14, fillna=True)\n",
    "    data['rsi'] = ta.momentum.rsi(data['close'], window=14, fillna=True)\n",
    "    data['mfi'] = ta.volume.money_flow_index(data['high'], data['low'], data['close'], data['volume'], window=14, fillna=True)\n",
    "\n",
    "    data = calculate_supertrend(data)\n",
    "\n",
    "    # مقداردهی اولیه متغیرها\n",
    "    cycle_open = False\n",
    "    cycle_type = None\n",
    "    potential_signal_time = None\n",
    "    potential_signal_type = None\n",
    "\n",
    "    # اضافه کردن ستون های trade_signal و cycle_status\n",
    "    data['trade_signal'] = None\n",
    "    data['cycle_status'] = None\n",
    "\n",
    "    # ذخیره مقادیر قبلی MFI\n",
    "    previous_mfi = data['mfi'].shift(1)\n",
    "\n",
    "    # حلقه اصلی برای بررسی سیگنال‌ها\n",
    "    for i in range(1, len(data)):\n",
    "        currentMfi = data.loc[i, 'mfi']\n",
    "        current_time = data.loc[i, 'timestamp']\n",
    "        in_uptrend = data.loc[i, 'in_uptrend']\n",
    "\n",
    "        # بررسی استمرار شرایط سیگنال پس از گذشت تأخیر\n",
    "        if potential_signal_time and (current_time - potential_signal_time).total_seconds() >= delay_period * 60:\n",
    "            if potential_signal_type == 'buy' and currentMfi > 20 and in_uptrend:\n",
    "                cycle_open = True\n",
    "                cycle_type = 'buy'\n",
    "                data.loc[i, 'trade_signal'] = 'buy'\n",
    "                data.loc[i, 'cycle_status'] = 'open'\n",
    "                cycle.append('open')\n",
    "            elif potential_signal_type == 'sell' and currentMfi < 80 and not in_uptrend:\n",
    "                cycle_open = True\n",
    "                cycle_type = 'sell'\n",
    "                data.loc[i, 'trade_signal'] = 'sell'\n",
    "                data.loc[i, 'cycle_status'] = 'open'\n",
    "                cycle.append('open')\n",
    "            potential_signal_time = None\n",
    "\n",
    "        # بررسی شرایط سیگنال بدون تأخیر\n",
    "        if not cycle_open:\n",
    "            if currentMfi < 20 and data.loc[i, 'adx'] > 25 and data.loc[i, 'rsi'] < 50 and in_uptrend:\n",
    "                potential_signal_time = current_time\n",
    "                potential_signal_type = 'buy'\n",
    "            elif currentMfi > 80 and data.loc[i, 'adx'] > 25 and data.loc[i, 'rsi'] > 50 and not in_uptrend:\n",
    "                potential_signal_time = current_time\n",
    "                potential_signal_type = 'sell'\n",
    "\n",
    "        # بررسی عبور برای بستن سیکل\n",
    "        if cycle_open:\n",
    "            if cycle_type == 'buy' and currentMfi > 80 and previous_mfi[i] < 80:\n",
    "                cycle_open = False\n",
    "                data.loc[i, 'trade_signal'] = 'sell'\n",
    "                data.loc[i, 'cycle_status'] = 'closed'\n",
    "                cycle.append('closed')\n",
    "            elif cycle_type == 'sell' and currentMfi < 20 and previous_mfi[i] > 20:\n",
    "                cycle_open = False\n",
    "                data.loc[i, 'trade_signal'] = 'buy'\n",
    "                data.loc[i, 'cycle_status'] = 'closed'\n",
    "                cycle.append('closed')\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# تابغ برای دریافت داده های تاریخی\n",
    "def fetch_historical_data(symbol, timeframe,limit):\n",
    "    if csv==False:\n",
    "        exchange=ccxt.bingx()\n",
    "        ohlcv=exchange.fetch_ohlcv(symbol,timeframe,limit=limit)\n",
    "        df=pd.DataFrame(ohlcv,columns=['timestamp','open','high','low','close','volume'])\n",
    "        df['timestamp']=pd.to_datetime(df['timestamp'],unit='ms')\n",
    "        # df['current'] = df['close']\n",
    "        df['current'] = 0\n",
    "        # df['current'].iloc[-1]=getLastPrice(df)\n",
    "        print(df[\"current\"].iloc[-1])\n",
    "        print(df[\"close\"].iloc[-1])\n",
    "        return df\n",
    "    else:\n",
    "        cv=pd.read_csv(\"data.csv\")\n",
    "\n",
    "        # cv['timestamp']=pd.to_datetime(cv['timestamp'],unit='ms')\n",
    "        cv2=cv.filter(['timestamp','open','high','low','close','volume'])\n",
    "        cv2['timestamp'] = pd.to_datetime(cv2['timestamp'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        # time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "        # timestamp = datetime.strptime(cv2['timestamp'], time_format)\n",
    "        # cv2['timestamp']=timestamp\n",
    "        return cv2\n",
    "\n",
    "\n",
    "# تابغ برای دریافت آحرین قیمت بازار\n",
    "def get_latest_market_price(symbol,timeframe='1m',limit=1):\n",
    "            if csv==False:\n",
    "                data=fetch_historical_data(symbol,timeframe,limit)\n",
    "\n",
    "                if not data.empty:\n",
    "                    return data['close'].iloc[-1]\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                 cv=pd.read_csv(\"data.csv\")\n",
    "                 return cv['close'].iloc[-1]\n",
    "\n",
    "def CalculatePerAcc(y_test, predictions, conf):\n",
    "    precision_per_class = precision_score(y_test, predictions, average=None)\n",
    "    # print(\"Precision per class:\")\n",
    "    # for idx, precision in enumerate(precision_per_class):\n",
    "    #     print(f\"Class {idx}: {precision:.2f}\")\n",
    "\n",
    "    # محاسبه تعداد نمونه‌های هر کلاس\n",
    "    class_counts = conf.sum(axis=1)\n",
    "\n",
    "    # محاسبه میانگین وزنی Precision دو کلاس اول\n",
    "    weight_0 = class_counts[0]\n",
    "    weight_1 = class_counts[1]\n",
    "    total_weight = weight_0 + weight_1\n",
    "\n",
    "    weighted_precision = (precision_per_class[0] * weight_0 + precision_per_class[1] * weight_1) / total_weight\n",
    "\n",
    "    # print(f\"Weighted Precision for classes 0 and 1: {weighted_precision:.2f}\")\n",
    "    return weighted_precision\n",
    "\n",
    "\n",
    "# def CalculatePerAcc(y_true, y_pred, conf_matrix):\n",
    "#     per_acc = (conf_matrix[1,1] + conf_matrix[0,0]) / np.sum(conf_matrix)\n",
    "#     return per_acc\n",
    "\n",
    "# def CalculatePerAcc(y_true, y_pred, conf_matrix):\n",
    "#     if conf_matrix.shape == (3, 3):\n",
    "#         per_acc = (conf_matrix[1, 1] + conf_matrix[0, 0]) / np.sum(conf_matrix)\n",
    "#         return per_acc\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "\n",
    "def calculate_auc_pr(y_true, y_pred):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    return auc(recall, precision)\n",
    "\n",
    "def CalculatePerAccGrid(y_true, y_pred):\n",
    "    precision_per_class = precision_score(y_true, y_pred, average='weighted')\n",
    "    conf = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    class_counts = conf.sum(axis=1)\n",
    "    weight_0 = class_counts[0]\n",
    "    weight_1 = class_counts[1]\n",
    "    total_weight = weight_0 + weight_1\n",
    "\n",
    "    weighted_precision = (precision_per_class[0] * weight_0 + precision_per_class[1] * weight_1) / total_weight\n",
    "\n",
    "    return weighted_precision\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# تابع تصمیم‌گیری برای برچسب‌گذاری با رای‌گیری\n",
    "def determine_label(row):\n",
    "    votes = []\n",
    "    \n",
    "    # اضافه کردن شرایط بر اساس اندیکاتورهای مختلف\n",
    "    if row['rsi'] > rsi_overbought:\n",
    "        votes.append(0)  # سل\n",
    "    elif row['rsi'] < rsi_oversold:\n",
    "        votes.append(1)  # بای\n",
    "    \n",
    "    if row['macd'] > macd_threshold:\n",
    "        votes.append(0)  # سل\n",
    "    elif row['macd'] < macd_threshold:\n",
    "        votes.append(1)  # بای\n",
    "    \n",
    "    # if row['adx'] > adx_threshold:\n",
    "    #     votes.append(0)  # سل\n",
    "    # elif row['adx'] < adx_threshold:\n",
    "    #     votes.append(1)  # بای\n",
    "    \n",
    "    if row['cci'] > cci_overbought:\n",
    "        votes.append(0)  # سل\n",
    "    elif row['cci'] < cci_oversold:\n",
    "        votes.append(1)  # بای\n",
    "    \n",
    "    if row['stochastic_oscillator'] > stochastic_high:\n",
    "        votes.append(0)  # سل\n",
    "    elif row['stochastic_oscillator'] < stochastic_low:\n",
    "        votes.append(1)  # بای\n",
    "    \n",
    "    # if row['ema_short'] > row['ema_long']:\n",
    "    #     votes.append(0)  # سل\n",
    "    # elif row['ema_short'] < row['ema_long']:\n",
    "    #     votes.append(1)  # بای\n",
    "    \n",
    "    # تعیین برچسب نهایی بر اساس اکثریت رای‌ها\n",
    "    if len(votes) == 0:\n",
    "        return 2  # No Action (هیچکدام)\n",
    "    else:\n",
    "        majority_vote = np.bincount(votes).argmax()\n",
    "        return majority_vote\n",
    "\n",
    "\n",
    "def ExtractToExcell(predictionNumber,fileName):\n",
    "    global lastSignalExcell\n",
    "    timestamp=data['timestamp'].iloc[-1]\n",
    "    current_time=timestamp.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "    lastSignalExcell=predictionNumber\n",
    "    # get_latest_market_price(symbol,'1m',1)\n",
    "            # قیمت فعلی و پیش‌بینی را در یک مجموعه داده ذخیره کنید\n",
    "    dataExcell = pd.DataFrame({\n",
    "        \"current_price\": data['close'].iloc[-1],\n",
    "        \"prediction\": predictionNumber,\n",
    "        \"timeStamp\":current_time\n",
    "        }, index=[0])\n",
    "\n",
    "\n",
    "        # data.to_csv(f\"Signal.csv\")\n",
    "        # dataExcell.to_csv(f\"Signal.csv\", mode='a', header=False, index=False)\n",
    "    file_path=fileName\n",
    "    if os.path.exists(file_path):\n",
    "        dataExcell.to_csv(file_path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "            dataExcell.to_csv(file_path, mode='w', header=True, index=False)\n",
    "\n",
    "\n",
    "def send_prediction_to_telegram(prediction,timestamp,symbol,accuracy,price,actionStatus,timeframe,best_k,profit,signalPrice,closedMethod):\n",
    "    if accuracy<expectedAccuracy:\n",
    "        # print('دقت مدل کمتر از 57 درصد است و سیگنال منتشر نمیشود')\n",
    "        percent=expectedAccuracy*100\n",
    "        print(f'accuracy is :{accuracy} and less than {percent}%')\n",
    "        return\n",
    "\n",
    "    current_time=timestamp.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # action=\"Buy\" if prediction==1 elif pre \"Sell\"\n",
    "    if prediction==0:\n",
    "        action=\"Sell\"\n",
    "    elif prediction==1:\n",
    "        action=\"Buy\"\n",
    "    else:\n",
    "        action=\"No Action\"\n",
    "\n",
    "    if actionStatus=='Open':\n",
    "         actionStatus_message=\"Cycle Open\"\n",
    "    elif actionStatus=='Close':\n",
    "        actionStatus_message= \"Cycle Closed By\"+closedMethod\n",
    "    else:\n",
    "        actionStatus_message=\"none\"\n",
    "\n",
    "    message= (\n",
    "        f\"Date and Time:{current_time} \\n\"\n",
    "        f\"Symbol: {symbol} \\n\"\n",
    "        f\"Action: {action} \\n\"\n",
    "        f\"Signal Price: {signalPrice} \\n\"\n",
    "        f\"TimeFrame: {timeframe} \\n\"\n",
    "        f\"Cycle Status: {actionStatus_message} \\n\"\n",
    "        f\"Current Price: {price} \\n\"\n",
    "        f\"Profit Percent: {profit} \\n\"\n",
    "        f\"Model Accuracy: {accuracy:.2f}\\n\"\n",
    "        f\"best_k: {best_k} \\n\"\n",
    "        f\"Robot ID: {BotId}\"\n",
    "    )\n",
    "\n",
    "    print(message)\n",
    "    # bot.sendMessage(chat_id=telegram_channel_id,text=message)\n",
    "    if csv==False:\n",
    "        try:\n",
    "            print(\"send\")\n",
    "            # bot.send_message(telegram_channel_id, message)\n",
    "        except:\n",
    "            print(\"could not connect to telegram\")\n",
    "\n",
    "    try:\n",
    "        ExtractToExcell(prediction,'SignalControl.csv')\n",
    "    except:\n",
    "            print(\"could write to SignalControl.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#تعریف اولیه داده\n",
    "data=fetch_historical_data(symbol,timeframe,limit)\n",
    "# data=calculate_rsi(data)\n",
    "# data=calculate_adx(data)\n",
    "# data=calculate_mfi(data)\n",
    "# data=calculate_linear_regression_channel(data)\n",
    "# data=calculate_supertrend(data)\n",
    "# data=calculate_macd(data)\n",
    "data=add_indicators(data)\n",
    "data['cycle_status']=None\n",
    "data['trade_signal']=None\n",
    "last_data_fetch_time=get_cyprus_time()\n",
    "# data=CloseSignalWithIndicators(data)\n",
    "# data=calculate_buy_sell_signalsSuperTrend(data)\n",
    "# data=calculate_di(data)\n",
    "# data=calculate_di(data)\n",
    "# test=calculate_di(data)\n",
    "# data['plus_di']=test[1][0]\n",
    "# data['plus_di'],data['minus_di']=\n",
    "#محاسبه سیگنال های خرید و فروش با استفاده از داده های بارگذاری شده\n",
    "# signals=calculate_buy_sell_signals(data)\n",
    "# signals=calculate_buy_sell_signals(data)\n",
    "\n",
    "#تعریف زمان برای آخرین بارگذاری داده ها\n",
    "\n",
    "#محاسبه سیگنال های خرید و فروش و بروزرسانی وضعیت سیکل\n",
    "# data=calculate_buy_sell_signals(data)\n",
    "#رسم نمودار\n",
    "# drawChart()\n",
    "# chart_thread = threading.Thread(target=drawChart)\n",
    "# chart_thread.start()\n",
    "\n",
    "\n",
    "def backtest(data,lot_size,intial_balance):\n",
    "    balance=initial=intial_balance\n",
    "    postion=0\n",
    "    trade_log=[]\n",
    "    cycle_log=[]\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        signal=data.loc[i,'trade_signal']\n",
    "        close_price=data.loc[i,'close']\n",
    "        cycle_status=data.loc[i,'cycle_status']\n",
    "\n",
    "        if signal=='buy' and postion==0:\n",
    "            #خرید و باز کردن سیکل\n",
    "            postion=lot_size/close_price\n",
    "            balance-=lot_size\n",
    "            trade_log.append(('buy',close_price,balance))\n",
    "            if cycle_status=='open':\n",
    "                cycle_log.append(('Cycle Opened',i))\n",
    "\n",
    "        elif signal=='sell' and postion >0:\n",
    "            #فروش و بستن سیکل\n",
    "            balance+=postion*close_price\n",
    "            postion=0\n",
    "            trade_log.append(('sell',close_price,balance))\n",
    "            if cycle_status=='closed':\n",
    "                cycle_log.append(('Cycle Closed',i))\n",
    "\n",
    "    #بستن پوزیشن باقی مانده در انتهای داده ها\n",
    "    if postion >0:\n",
    "        balance+=postion * data.iloc[-1]['close']\n",
    "        trade_log.append(('sell',data.iloc[-1]['close'],balance))\n",
    "        postion=0\n",
    "\n",
    "    return balance,trade_log,cycle_log\n",
    "\n",
    "\n",
    "    #مثال برای نمایش نتایج  بک تست\n",
    "# final_balance,trades,cycles=backtest(data,lot_size=1000,initial_balance=10000)\n",
    "\n",
    "# print(f\"Final Balance:{final_balance}\")\n",
    "# for trade in trades:\n",
    "#     print(f\"Trade: {trade}\")\n",
    "# for cycle in cycles:\n",
    "#     print(f\"Cycle: {cycle}\")\n",
    "\n",
    "\n",
    "# final_balance,trades,cycles=backtest(data,lot_size=1000,intial_balance=10000)\n",
    "\n",
    "# print(f\"Final Balance: {final_balance}\")\n",
    "# for trade in trades:\n",
    "#     print(f\"Trade: {trade}\")\n",
    "# for cycle in cycles:\n",
    "#     print(f\"Cycle: {cycle}\")\n",
    "# تابع برای تعیین مقدار ستون target براساس درصد تغییر\n",
    "def determine_target(percent_change,expectedChange):\n",
    "    if percent_change > expectedChange:\n",
    "        return 1\n",
    "    elif percent_change < -expectedChange:\n",
    "        return 0\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# حلقه اصلی\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def MlpClassifier():\n",
    "    # Initialize empty dictionaries to store best hyperparameters and models\n",
    "    best_params = {}\n",
    "    best_models = {}\n",
    "    # Initialize an empty list to store the best models\n",
    "    all_best_models = []  # This list will store the best model for each column\n",
    "\n",
    "    # Assuming `data` is already defined and contains your dataset\n",
    "    timestamp = data['timestamp'].iloc[-1]\n",
    "    current_time = timestamp.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    data.to_csv(f\"Data{current_time}.csv\")\n",
    "\n",
    "    # Extract the target variable (label) for the current column\n",
    "    y = data[\"target\"]\n",
    "    X = data[['rsi', 'mid_channel', 'upper_channel', 'lower_channel', 'mfi']]\n",
    "    X = X.fillna(X.mean())\n",
    "\n",
    "    # Calculate the length of the data\n",
    "    data_length = len(X)\n",
    "\n",
    "    # Calculate the number of test data points (20% of the data)\n",
    "    test_size = int(data_length * 0.02)\n",
    "\n",
    "    # Separate the last 20% of the data for testing\n",
    "    X_train = X[:-test_size]\n",
    "    X_test = X[-test_size:-shiftedNumber]\n",
    "    y_train = y[:-(test_size)]\n",
    "    y_test = y[-test_size:-shiftedNumber]\n",
    "\n",
    "    # Define hyperparameters to test for MLP\n",
    "    hidden_layer_sizes_options = [(50, 50), (100,), (50, 100, 50)]\n",
    "    learning_rate_options = ['constant', 'invscaling', 'adaptive']\n",
    "    best_acc = 0  # Initialize the best accuracy to 0\n",
    "\n",
    "    # Iterate over the hyperparameters to find the best model\n",
    "    for hidden_layer_sizes in hidden_layer_sizes_options:\n",
    "        for learning_rate in learning_rate_options:\n",
    "            # Create and train an MLP model\n",
    "            mlp_model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, learning_rate=learning_rate, max_iter=1000)\n",
    "            mlp_model.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate the model's performance on the testing set\n",
    "            accuracy = accuracy_score(y_test, mlp_model.predict(X_test))\n",
    "\n",
    "            # Update best values if current accuracy is higher\n",
    "            if accuracy > best_acc:\n",
    "                best_acc = accuracy\n",
    "                best_params = {'hidden_layer_sizes': hidden_layer_sizes, 'learning_rate': learning_rate}\n",
    "                best_model = mlp_model\n",
    "\n",
    "    # Store the best hyperparameters and model\n",
    "    best_models[0] = best_model\n",
    "\n",
    "    # Append the best model to the all_best_models list\n",
    "    all_best_models.append(best_models[0])\n",
    "\n",
    "    predictions = all_best_models[0].predict(X_test)\n",
    "\n",
    "    accuracy=recall_score(y_test,all_best_models[0].predict(X_test),average='macro')\n",
    "    conf = confusion_matrix(y_test,predictions)\n",
    "    print(f\"confusion Matrix:\\n{conf}\")\n",
    "    print('metrics.classification_report:=\\n',metrics.classification_report(y_test,predictions))\n",
    "    print('recall_score = ',recall_score(y_test,predictions,average='macro') )\n",
    "\n",
    "    accuracy = accuracy_score(y_test, all_best_models[0].predict(X_test))\n",
    "    if accuracy > expectedAccuracy:\n",
    "        predictions = all_best_models[0].predict(X[-1:])\n",
    "    array = np.array(predictions)\n",
    "    predictionNumber = int(array[-1])\n",
    "    return all_best_models, accuracy, predictionNumber\n",
    "\n",
    "\n",
    "def Knn(X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    # pca = PCA(n_components=0.95)\n",
    "    # X_train = pca.fit_transform(X_train)\n",
    "    # X_test = pca.transform(X_test)\n",
    "   \n",
    "\n",
    "    # از الگوریتم knn  برای پیش بینی استفاده کردیم\n",
    "    # Initialize empty dictionaries to store best n_neighbors and models\n",
    "    best_n_neighbors = {}\n",
    "    best_models = {}\n",
    "    #برای هر ستون یک مدل جداگانه اموزش دادیم و مقادیر بهترین  تعداد همسایه برای هر ستون پیدا کردیم\n",
    "    # مدلی که بیشترین دقت را داشت ذخیره کردیم\n",
    "    # Initialize an empty list to store the best models\n",
    "    all_best_models = []  # This list will store the best model for each column\n",
    "\n",
    "    # Iterate through each column (feature)\n",
    "\n",
    "    # y = data[\"target\"]\n",
    "    # X = data[['rsi', 'macd', 'bollinger_hband', 'bollinger_lband',  'mfi', 'stochastic','mid_channel','close']]\n",
    "\n",
    "\n",
    "    # pca = PCA(n_components=0.95)  # Keep 95% of the variance\n",
    "    # X = pca.fit_transform(X)\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    #X=X.fillna(X.mean())\n",
    "    # timestamp=data['timestamp'].iloc[-1]\n",
    "    # current_time=timestamp.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    # data.to_csv(f\"Data{current_time}.csv\")\n",
    "\n",
    "        # فرض می‌کنیم X و y دیتاهای شما هستند\n",
    "    # data_length = len(X)\n",
    "\n",
    "    # محاسبه تعداد داده‌های تست (20% انتهایی)\n",
    "    # test_size = int(data_length * percentTest)\n",
    "\n",
    "    # جدا کردن 20% انتهایی داده‌ها برای تست\n",
    "    # X_train = X[:-test_size]\n",
    "    # X_test = X[-test_size:-shiftedNumber]\n",
    "    # y_train = y[:-(test_size)]\n",
    "    # y_test = y[-test_size:-shiftedNumber]\n",
    "\n",
    "\n",
    "    # X=data[['rsi','adx','mfi','supertrend']]\n",
    "\n",
    "    # scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "            # نرمال سازی X\n",
    "    # X = scaler.fit_transform(X)\n",
    "    knn_model_best=[]\n",
    "    # Find the optimal n_neighbors for this column\n",
    "    best_n, best_acc = 0, 0  # Initialize best values\n",
    "    # X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "    for n_neighbors in range(3, 100):  # Test different n_neighbors values\n",
    "        # Split data into training and testing sets\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "        # Create and train a KNN model\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model's performance on the testing set\n",
    "        # accuracy = accuracy_score(y_test, knn_model.predict(X_test))\n",
    "        # accuracy=recall_score(y_test,knn_model.predict(X_test),average='macro')\n",
    "        perdictTemp=knn_model.predict(X_train)\n",
    "        conf = confusion_matrix(y_train,perdictTemp)\n",
    "        accuracy=CalculatePerAcc(y_train, perdictTemp, conf)\n",
    "    #  print(accuracy)\n",
    "\n",
    "        # Update best values if current accuracy is higher\n",
    "        if accuracy > best_acc:\n",
    "            best_n, best_acc = n_neighbors, accuracy\n",
    "            knn_model_best = knn_model\n",
    "\n",
    "    # Store the best n_neighbors and model for this column\n",
    "    best_n_neighbors[0] = best_n\n",
    "    best_models[0] = knn_model_best\n",
    "\n",
    "    # Append the best model for this column to the all_best_models list\n",
    "    all_best_models.append(best_models[0])\n",
    "\n",
    "    predictions=all_best_models[0].predict(X_test)\n",
    "\n",
    "\n",
    "    # data[\"predictions\"]=predictions\n",
    "    # accuracy = accuracy_score(y_test, all_best_models[0].predict(X_test))\n",
    "    # accuracy=recall_score(y_test,all_best_models[0].predict(X_test),average='macro')\n",
    "    conf = confusion_matrix(y_test,predictions)\n",
    "    accuracy = CalculatePerAcc(y_test, predictions, conf)\n",
    "\n",
    "    print(f\"confusion Matrix:\\n{conf}\")\n",
    "    print('metrics.classification_report:=\\n',metrics.classification_report(y_test,predictions))\n",
    "    print('recall_score = ',recall_score(y_test,predictions,average='macro') )\n",
    "    print(f'accuracy:{accuracy}')\n",
    "    # print(f\"Weighted Precision for classes 0 and 1: {CalculatePerAcc(y_test, predictions, conf):.2f}\")\n",
    "    # predictions=all_best_models[0].predict(X[-1:])\n",
    "\n",
    "    # array=np.array(predictions)\n",
    "    # predictionNumber= int( array [-1] )\n",
    "    # print(f'predictions:{predictions}')\n",
    "\n",
    "    # if predictionNumber !=  lastSignalExcell :\n",
    "    \n",
    "    #     ExtractToExcell(predictionNumber,'Signal.csv')\n",
    "\n",
    "    if accuracy>expectedAccuracy :\n",
    "        return predictions,all_best_models[0],accuracy\n",
    "    \n",
    "    return predictions,all_best_models[0],accuracy\n",
    "    # else:\n",
    "    #     return None,None,None\n",
    "\n",
    "\n",
    "def SvmOld(X_train, X_test, y_train, y_test):\n",
    "    # Perform PCA on training and test data\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # Define values to iterate over for C and gamma\n",
    "    c_values = [0.01, 0.1, 1, 10, 100]\n",
    "    gamma_values = [0.01, 0.001, 0.005, 0.5, 0.1, 1, 10, 100]\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'C': c_values,\n",
    "        'gamma': gamma_values,\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "\n",
    "    # Initialize SVM classifier\n",
    "    svm_model = SVC()\n",
    "\n",
    "    # Initialize GridSearchCV with cross-validation\n",
    "    grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "    # Fit GridSearchCV on PCA-transformed training data\n",
    "    grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "    # Best accuracy\n",
    "    best_accuracy = grid_search.best_score_\n",
    "    print(f\"Best cross-validation accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Train final SVM model with best parameters\n",
    "    best_svm_model = SVC(**best_params)\n",
    "    best_svm_model.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Predict using the best model on test set\n",
    "    final_predictions = best_svm_model.predict(X_test_pca)\n",
    "    final_predictions_train = best_svm_model.predict(X_train_pca)\n",
    "\n",
    "    # Calculate accuracy and confusion matrix on test set\n",
    "    final_acc = accuracy_score(y_test, final_predictions)\n",
    "    final_conf = confusion_matrix(y_test, final_predictions)\n",
    "\n",
    "    # Calculate accuracy and confusion matrix on training set\n",
    "    final_acc_train = accuracy_score(y_train, final_predictions_train)\n",
    "    final_conf_train = confusion_matrix(y_train, final_predictions_train)\n",
    "\n",
    "    # Print final metrics\n",
    "    print(f\"Final accuracy on test set: {final_acc * 100:.2f}%\")\n",
    "    print(f\"Confusion matrix on test set:\\n{final_conf}\")\n",
    "    print(f\"Final accuracy on training set: {final_acc_train * 100:.2f}%\")\n",
    "    print(f\"Confusion matrix on training set:\\n{final_conf_train}\")\n",
    "\n",
    "    # Print classification report on test set\n",
    "    print('Classification Report on test set:\\n', classification_report(y_test, final_predictions))\n",
    "\n",
    "    return final_predictions, best_svm_model\n",
    "\n",
    "# Example usage:\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# final_predictions, best_svm_model = Svm(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "def Svm(X_train, X_test, y_train, y_test):\n",
    "    pca = PCA(n_components=0.95)\n",
    "    # X_train_pca = pca.fit_transform(X_train)\n",
    "    # X_test_pca = pca.transform(X_test)\n",
    "    X_train_pca = X_train\n",
    "    X_test_pca = X_test\n",
    "    # Define values to iterate over for C and gamma\n",
    "    c_values = [0.01, 0.1, 1, 10, 100, 1000] \n",
    "    gamma_values = [0.01,0.001,0.005,0.5, 0.1, 1, 10, 100,1000,0.0001,0.9,0.8,0.7,0.6,0.4]\n",
    "    # gamma_values = [0.01,0.001,0.005,0.5, 0.1, 1, 10, 100,1000,0.0001,0.9,0.8,0.7,0.6,0.4]\n",
    "\n",
    "    best_acc = -1\n",
    "    best_params = {'C': None, 'gamma': None}\n",
    "\n",
    "    # Iterate over all combinations of C and gamma\n",
    "    for C in c_values:\n",
    "        for gamma in gamma_values:\n",
    "            # Initialize SVM classifier with current parameters\n",
    "            svm_model = SVC(C=C, gamma=gamma, kernel='rbf')\n",
    "\n",
    "            # Fit SVM model on PCA transformed training data\n",
    "            svm_model.fit(X_train_pca, y_train)\n",
    "\n",
    "            # Predict on test data\n",
    "            # svm_predictions = svm_model.predict(X_test_pca)\n",
    "            svm_predictions = svm_model.predict(X_test_pca)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            # acc = CalculatePerAccGrid(y_test, svm_predictions)\n",
    "            # acc = CalculatePerAccGrid(y_test, svm_predictions)\n",
    "            acc = precision_score(y_test, svm_predictions, average='weighted')\n",
    "            # acc = precision_score(y_test, svm_predictions, average='weighted')\n",
    "\n",
    "            # Print current parameters and accuracy\n",
    "            print(f\"C={C}, gamma={gamma}, Accuracy={acc * 100:.2f}%\")\n",
    "\n",
    "            # Check if current model is better than previous best\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_params['C'] = C\n",
    "                best_params['gamma'] = gamma\n",
    "\n",
    "    print(f\"Best parameters found: {best_params}\")\n",
    "    print(f\"Best accuracy found: {best_acc * 100:.2f}%\")\n",
    "\n",
    "    # Train final SVM model with best parameters\n",
    "    best_svm_model = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel='rbf')\n",
    "    best_svm_model.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Predict using the best model\n",
    "    final_predictions = best_svm_model.predict(X_test_pca)\n",
    "    final_predictions2 = best_svm_model.predict(X_train_pca)\n",
    "\n",
    "    final_conf2 = confusion_matrix(y_train, final_predictions2)\n",
    "\n",
    "    # Calculate accuracy and confusion matrix\n",
    "    final_acc = accuracy_score(y_test, final_predictions)\n",
    "    final_conf = confusion_matrix(y_test, final_predictions)\n",
    "    print('metrics.classification_report:=\\n',metrics.classification_report(y_test,final_predictions))\n",
    "    print('metrics.classification_report2:=\\n',metrics.classification_report(y_train,final_predictions2))\n",
    "    print(f\"Final accuracy: {final_acc * 100:.2f}%\")\n",
    "    print(f\"Confusion matrix:\\n{final_conf}\")\n",
    "    print(f\"Confusion matrix2:\\n{final_conf2}\")\n",
    "\n",
    "    return final_predictions, best_svm_model\n",
    "def Lstmold(X_train, X_test, y_train, y_test, expectedLstmModel=expectedLstmModel):\n",
    "    # pca = PCA(n_components=0.95)\n",
    "    # X_train_pca = pca.fit_transform(X_train)\n",
    "    # X_test_pca = pca.transform(X_test)\n",
    "\n",
    "\n",
    "    X_train_pca = X_train\n",
    "    X_test_pca = X_test\n",
    "\n",
    "    # Reshape for LSTM input\n",
    "    X_train_lstm = X_train_pca.values.reshape((-1, X_train_pca.shape[1], 1))\n",
    "    X_test_lstm = X_test_pca.values.reshape((-1, X_test_pca.shape[1], 1))\n",
    "\n",
    "    # Define the LSTM model\n",
    "    model_lstm = Sequential()\n",
    "\n",
    "    # Define the model architecture\n",
    "    model_lstm.add(Input(shape=(X_train_pca.shape[1], 1)))\n",
    "    model_lstm.add(LSTM(units=100, return_sequences=True, activation='relu'))\n",
    "    model_lstm.add(LSTM(units=50, activation='relu'))\n",
    "    model_lstm.add(Dropout(0.2))\n",
    "    model_lstm.add(Dense(units=25, activation='relu'))\n",
    "    model_lstm.add(Dense(units=1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "    # Compile the model\n",
    "    model_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy')\n",
    "\n",
    "    acc = -1\n",
    "    while acc < expectedLstmModel:\n",
    "        # Train the LSTM model\n",
    "        model_lstm.fit(X_train_lstm, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "        # Predict with the LSTM model\n",
    "        lstm_predictions = model_lstm.predict(X_test_lstm)\n",
    "        lstm_predictions = (lstm_predictions > 0.5).astype(int)\n",
    "\n",
    "        # Calculate confusion matrix and prediction accuracy\n",
    "        conf = confusion_matrix(y_test, lstm_predictions)\n",
    "        accuracy_lstm = accuracy_score(y_test, lstm_predictions)\n",
    "        acc = accuracy_lstm\n",
    "        print(f\"LSTM Accuracy: {accuracy_lstm * 100:.2f}%\")\n",
    "\n",
    "    return lstm_predictions, model_lstm, accuracy_lstm\n",
    "\n",
    "def Lstm(X_train, X_test, y_train, y_test):\n",
    "\n",
    "\n",
    "\n",
    "    model_lstm = Sequential()\n",
    "    \n",
    "    # Define the model architecture\n",
    "    model_lstm.add(Input(shape=(X_train.shape[1], 1)))\n",
    "    model_lstm.add(LSTM(units=100, return_sequences=True, activation='relu'))\n",
    "    # model_lstm.add(Dropout(0.2))\n",
    "    model_lstm.add(LSTM(units=50, activation='relu'))\n",
    "    model_lstm.add(Dropout(0.2))\n",
    "    model_lstm.add(Dense(units=25, activation='relu'))\n",
    "    model_lstm.add(Dense(units=1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy')\n",
    "    \n",
    "    # Reshape the features for LSTM\n",
    "    X_train_lstm = X_train.values.reshape((-1, X_train.shape[1], 1))\n",
    "    X_test_lstm = X_test.values.reshape((-1, X_test.shape[1], 1))\n",
    "\n",
    "    # Setup EarlyStopping\n",
    "    # early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the LSTM model\n",
    "    # model_lstm.fit(X_train_lstm, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "    acc=-1\n",
    "    while acc<expectedLstmModel:\n",
    "        model_lstm.fit(X_train_lstm, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "        # Predict with the LSTM model\n",
    "        lstm_predictions = model_lstm.predict(X_test_lstm)\n",
    "        lstm_predictions = (lstm_predictions > 0.5).astype(int)  # Convert to 0 and 1\n",
    "\n",
    "        # Calculate confusion matrix and prediction accuracy\n",
    "        conf = confusion_matrix(y_test, lstm_predictions)\n",
    "        accuracy_lstm = accuracy_score(y_test, lstm_predictions)\n",
    "        acc=accuracy_lstm\n",
    "        print(f\"LSTM Accuracy: {accuracy_lstm * 100:.2f}%\")\n",
    "    # accuracy_lstm=round(((accuracy_lstm)*100),2)\n",
    "    return lstm_predictions, model_lstm,accuracy_lstm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def TrainLstmSVm():\n",
    "    global data\n",
    "    global accuracy\n",
    "    # global LstmAccuracy\n",
    "    global scaler\n",
    "    accuracy=0\n",
    "    LstmAccuracy=0\n",
    "    CombineAccuracy=0\n",
    "    combined_predictions=-3\n",
    "    # data=data.dropna()\n",
    "    data = dropNaFix(data)\n",
    "    y = data[\"target\"]\n",
    "    # X = data[['rsi', 'macd', 'bollinger_hband', 'bollinger_lband',  'mfi', 'stochastic','mid_channel','current']]\n",
    "    # X = data[['close','volume','rsi','macd','macd_diff','williams_r','dpo']]\n",
    "    X = data[['stochastic', 'macd','close','volume']]\n",
    "\n",
    "    # pca = PCA(n_components=0.95)  # Keep 95% of the variance\n",
    "    # X = pca.fit_transform(X)\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    #X=X.fillna(X.mean())\n",
    "    timestamp=data['timestamp'].iloc[-1]\n",
    "    current_time=timestamp.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    data.to_csv(f\"Data{current_time}.csv\")\n",
    "\n",
    "        # فرض می‌کنیم X و y دیتاهای شما هستند\n",
    "    data_length = len(X)\n",
    "\n",
    "    # محاسبه تعداد داده‌های تست (20% انتهایی)\n",
    "    test_size = int(data_length * percentTest)\n",
    "\n",
    "    # جدا کردن 20% انتهایی داده‌ها برای تست\n",
    "    # X_train = X[:-test_size]\n",
    "    # X_test = X[-test_size:-shiftedNumber]\n",
    "    # y_train = y[:-(test_size)]\n",
    "    # y_test = y[-test_size:-shiftedNumber]\n",
    "    \n",
    "    X_train = X[:-test_size]\n",
    "    X_test = X[-test_size:-shiftedNumber]\n",
    "    y_train = y[:-test_size]\n",
    "    y_test = y[-test_size:-shiftedNumber]\n",
    "    finalScore=-3\n",
    "    # نرمال‌سازی داده‌ها\n",
    "   # X_train = scaler.fit_transform(X_train)\n",
    "    #X_test = scaler.transform(X_test)\n",
    "   # # ویژگی‌ها و برچسب‌ها را تعیین کنید\n",
    "    # while expectedCombineModel>accuracy or  CombineAccuracy<0.6 :\n",
    "\n",
    "        \n",
    " \n",
    "\n",
    "\n",
    "    # آموزش مدل LSTM\n",
    "    lstm_predictions,lstm_Model,LstmAccuracy = Lstm(X_train, X_test, y_train, y_test)\n",
    "    knn_predictions,knn_Model,KnnAccuracy = Knn(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # آموزش مدل SVM\n",
    "    svm_predictions,svm_Model = Svm(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # finalScore=lstm_predictions\n",
    "    results=[]\n",
    "    for i in range (X_test.shape[0]):\n",
    "        if lstm_predictions[i]==knn_predictions[i]:\n",
    "            results.append(lstm_predictions[i])\n",
    "        elif lstm_predictions[i]==svm_predictions[i]:\n",
    "            results.append(lstm_predictions[i])\n",
    "        else:\n",
    "            results.append(svm_predictions[i])\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    # svm_Model=None\n",
    "    # combined_model=None\n",
    "    # ترکیب پیش‌بینی‌های LSTM و اسکورهای SVM\n",
    "    # combined_X = np.column_stack((lstm_predictions, scores))\n",
    "\n",
    "        # ساخت مدل ترکیبی (مثلاً Random Forest)\n",
    "    # combined_model = RandomForestClassifier()\n",
    "    # combined_model.fit(combined_X, y_test)\n",
    "    # # پیش‌بینی خرید و فروش با مدل ترکیبی\n",
    "    # combined_predictions = combined_model.predict(combined_X)\n",
    "\n",
    "    # combined_predictions=lstm_predictions\n",
    "    print(f\"shape YTest:{y_test.shape}\")\n",
    "    # results=np.array(results)\n",
    "    # print(f\"Shape Result{results.shape}\")\n",
    "    # results = np.array(results.values, dtype=object)\n",
    "    # results = results.values\n",
    "    results = [x.item() if isinstance(x, np.ndarray) else x for x in results]\n",
    "    results = np.array(results)\n",
    "    print(results)\n",
    "    # results = np.array(results)\n",
    "    conf=confusion_matrix(y_test,results)\n",
    "    # conf=confusion_matrix(y_test,combined_predictions)\n",
    "    # محاسبه درصد درستی پیش‌بینی‌ها\n",
    "    accuracy = CalculatePerAcc(y_test, results,conf)\n",
    "    # accuracy = CalculatePerAcc(y_test, combined_predictions,conf)\n",
    "    print(f\"accuracy {accuracy * 100:.2f}%\")\n",
    "    CombineAccuracy = accuracy_score(y_test, results)\n",
    "    # CombineAccuracy = accuracy_score(y_test, combined_predictions)\n",
    "    print(f\"accuracy Combine {CombineAccuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "    # X_test_lstm = X[-1:].values.reshape((-1, 8, 1))\n",
    "    # lstm_predictions=lstm_Model.predict(X_test_lstm)\n",
    "    # lstm_predictions = (lstm_predictions > 0.5).astype(int)\n",
    "    # svm_predictions = svm_Model.predict(X[-1:])\n",
    "\n",
    "\n",
    "    # ایجاد اسکور بر اساس پیش‌بینی‌های SVM\n",
    "    # scores = [0 if prediction == 0 else 1 for prediction in svm_predictions]\n",
    "    # محاسبه درصد درستی پیش‌بینی‌ها\n",
    "    # combined_X = np.column_stack((lstm_predictions, scores))\n",
    "\n",
    "    # ساخت مدل ترکیبی (مثلاً Random Forest)\n",
    "    # combined_model = RandomForestClassifier()\n",
    "    # combined_model.fit(combined_X, y_test)\n",
    "\n",
    "    # پیش‌بینی خرید و فروش با مدل ترکیبی\n",
    "    # combined_predictions = combined_model.predict(combined_X)\n",
    "    # conf = confusion_matrix(y_test,combined_predictions)\n",
    "    # accuracy=CalculatePerAcc(y_test, combined_predictions, conf)\n",
    "    print(f\"confusion Matrix:\\n{conf}\")\n",
    "    print('metrics.classification_report:=\\n',metrics.classification_report(y_test,results))\n",
    "    # print('metrics.classification_report:=\\n',metrics.classification_report(y_test,combined_predictions))\n",
    "    # return lstm_Model,svm_Model,combined_model,accuracy\n",
    "    return lstm_Model,svm_Model,knn_Model,accuracy\n",
    "\n",
    "def Election(lstm_Model,svm_Model,knn_Model):\n",
    "    global data\n",
    "    global accuracy\n",
    "    data = dropNaFix(data)\n",
    "    y = data[\"target\"]\n",
    "    # X = data[['rsi', 'macd', 'bollinger_hband', 'bollinger_lband',  'mfi', 'stochastic','mid_channel','close']]\n",
    "    # X2 = data[['rsi', 'macd', 'bollinger_hband', 'bollinger_lband',  'mfi', 'stochastic','mid_channel','current']]\n",
    "    # X2 = data[['close','volume','rsi','macd','macd_diff','williams_r','dpo']]\n",
    "    X2 = data[['stochastic', 'macd','close','volume']]\n",
    "\n",
    "    pca = PCA(n_components=0.95)\n",
    "    \n",
    "\n",
    "\n",
    "       # فرض می‌کنیم X و y دیتاهای شما هستند\n",
    "    data_length = len(X2)\n",
    "\n",
    "    # محاسبه تعداد داده‌های تست (20% انتهایی)\n",
    "    test_size = int(data_length * percentTest)\n",
    "  # x2=scaler.transform(X2)\n",
    "   # x=scaler.transform(X2)\n",
    "    x2=X2\n",
    "    x=X2\n",
    "\n",
    "    X_Predict = x2[-1:]       \n",
    "    X_test = x[-test_size:-shiftedNumber]\n",
    "    y_test = y[-test_size:-shiftedNumber]\n",
    "    # X_test_pca = pca.fit_transform(x[:-test_size])\n",
    "    # X_predict_pca = pca.transform(X_Predict)\n",
    "    X_test_pca = X_test\n",
    "    X_predict_pca = X_Predict\n",
    "\n",
    "\n",
    "    # pca = PCA(n_components=0.95)  # Keep 95% of the variance\n",
    "    # X = pca.fit_transform(X)\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    #X=X.fillna(X.mean())\n",
    "    timestamp=data['timestamp'].iloc[-1]\n",
    "    current_time=timestamp.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    data.to_csv(f\"Data{current_time}.csv\")\n",
    "\n",
    " \n",
    "    \n",
    "    # محاسبه درصد درستی پیش‌بینی‌ها\n",
    "    print(f\" x2[-1] :{X2[-1:]}\")\n",
    "    print(f\" lastTest :{X_Predict}\")\n",
    "   \n",
    "    \n",
    "    X_Predict_lstm = X_Predict.values.reshape((-1,  X_Predict.shape[1], 1))\n",
    "    X_test_lstm = X_test.values.reshape((-1, X_test.shape[1], 1))\n",
    "\n",
    "    lstm_predictions=lstm_model.predict(X_Predict_lstm)\n",
    "    lstm_predictionsTest=lstm_model.predict(X_test_lstm)\n",
    "\n",
    "    lstm_predictions = (lstm_predictions > 0.5).astype(int)\n",
    "    lstm_predictionsTest = (lstm_predictionsTest > 0.5).astype(int)\n",
    "\n",
    "    \n",
    "    svm_predictions = svm_model.predict(X_predict_pca)\n",
    "    svm_predictionsTest = svm_model.predict(X_test_pca)\n",
    "    # ایجاد اسکور بر اساس پیش‌بینی‌های SVM\n",
    "    svm_predictions = [0 if prediction == 0 else 1 for prediction in svm_predictions]\n",
    "    svm_predictionsTest = [0 if prediction2 == 0 else 1 for prediction2 in svm_predictionsTest]\n",
    "    # محاسبه درصد درستی پیش‌بینی‌ها\n",
    "    knn_predictions = knn_Model.predict(X_predict_pca)\n",
    "    knn_predictionsTest = knn_Model.predict(X_test_pca)\n",
    "   # print(f\" combined_X :{combined_X}\")\n",
    "    #print(f\" combined_XTest :{combined_XTest}\")\n",
    "\n",
    "    resultTest=[]\n",
    "    for i in range (X_test.shape[0]):\n",
    "        if lstm_predictionsTest[i]==knn_predictionsTest[i]:\n",
    "            resultTest.append(lstm_predictionsTest[i])\n",
    "        elif lstm_predictionsTest[i]==svm_predictionsTest[i]:\n",
    "            resultTest.append(lstm_predictionsTest[i])\n",
    "        else:\n",
    "            resultTest.append(svm_predictionsTest[i])\n",
    "    resultTest = [x.item() if isinstance(x, np.ndarray) else x for x in resultTest]\n",
    "    resultTest = np.array(resultTest)\n",
    "    print(resultTest)\n",
    "    conf=confusion_matrix(y_test,resultTest)\n",
    "    accuracy = CalculatePerAcc(y_test, resultTest,conf)\n",
    "    print(f\"accuracy {accuracy * 100:.2f}%\")\n",
    "    CombineAccuracy = accuracy_score(y_test, resultTest)\n",
    "    print(f\"accuracy Combine {CombineAccuracy * 100:.2f}%\")\n",
    "    print(f\"confusion Matrix:\\n{conf}\")\n",
    "    print('metrics.classification_report:=\\n',metrics.classification_report(y_test,resultTest))\n",
    "\n",
    "\n",
    "    print(f\" Predict Lstm {lstm_predictions[0]}\")\n",
    "    print(f\" Predict Svm {svm_predictions[0]}\")\n",
    "    print(f\" Predict Knn {knn_predictions[0]}\")\n",
    "    results=-3\n",
    "    # if lstm_predictions[0]==knn_predictions[0]:\n",
    "    #     results=lstm_predictions[0]\n",
    "    # elif lstm_predictions[0]==svm_predictions[0]:\n",
    "    #     results=lstm_predictions[0]\n",
    "    # else:\n",
    "    #     results=svm_predictions[0]\n",
    "   # combined_predictions=results\n",
    "    # combined_predictions=results\n",
    "    combined_predictions=svm_predictions[0]\n",
    "\n",
    "\n",
    "    #combined_predictionsTest=lstm_predictionsTest\n",
    "    #combined_predictions=lstm_predictions\n",
    "    # print(f\"درصد درستی پیش‌بینی ترکیبی: {accuracy * 100:.2f}%\")\n",
    "    # print(f\"combine prediction: {combined_predictions}\")\n",
    "\n",
    "    # conf = confusion_matrix(y_test,combined_predictionsTest)\n",
    "    # accuracy = CalculatePerAcc(y_test, combined_predictionsTest, conf)\n",
    "\n",
    "    # print(f\"confusion Matrix:\\n{conf}\")\n",
    "    # print('metrics.classification_report:=\\n',metrics.classification_report(y_test,combined_predictionsTest))\n",
    "    # return True,accuracy,combined_predictions\n",
    "\n",
    "    \n",
    "    # array=np.array(combined_predictions)\n",
    "    # predictionNumber= int( array [-1] )\n",
    "    predictionNumber= combined_predictions\n",
    "    print(f'combined_predictions:{combined_predictions}')\n",
    "    return True,accuracy,predictionNumber\n",
    "\n",
    "\n",
    "\n",
    "def PredictCombine(lstm_model,svm_model,combine_model):\n",
    "\n",
    "    global data\n",
    "    global accuracy\n",
    "\n",
    "    data = dropNaFix(data)\n",
    "    y = data[\"target\"]\n",
    "    # X = data[['rsi', 'macd', 'bollinger_hband', 'bollinger_lband',  'mfi', 'stochastic','mid_channel','close']]\n",
    "    # X2 = data[['rsi', 'macd', 'bollinger_hband', 'bollinger_lband',  'mfi', 'stochastic','mid_channel','current']]\n",
    "    X2 = data[['close','volume','rsi','macd','macd_diff','williams_r','dpo']]\n",
    "\n",
    "\n",
    "       # فرض می‌کنیم X و y دیتاهای شما هستند\n",
    "    data_length = len(X2)\n",
    "\n",
    "    # محاسبه تعداد داده‌های تست (20% انتهایی)\n",
    "    test_size = int(data_length * percentTest)\n",
    "  # x2=scaler.transform(X2)\n",
    "   # x=scaler.transform(X2)\n",
    "    x2=X2\n",
    "    x=X2\n",
    "\n",
    "    X_Predict = x2[-1:]\n",
    "    X_test = x[-test_size:-shiftedNumber]\n",
    "    y_test = y[-test_size:-shiftedNumber]\n",
    "    \n",
    "\n",
    "\n",
    "    # pca = PCA(n_components=0.95)  # Keep 95% of the variance\n",
    "    # X = pca.fit_transform(X)\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    #X=X.fillna(X.mean())\n",
    "    timestamp=data['timestamp'].iloc[-1]\n",
    "    current_time=timestamp.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    data.to_csv(f\"Data{current_time}.csv\")\n",
    "\n",
    " \n",
    "    \n",
    "    # محاسبه درصد درستی پیش‌بینی‌ها\n",
    "    print(f\" x2[-1] :{X2[-1:]}\")\n",
    "    print(f\" lastTest :{X_Predict}\")\n",
    "   \n",
    "    \n",
    "    X_Predict_lstm = X_Predict.values.reshape((-1, 7, 1))\n",
    "    X_test_lstm = X_test.values.reshape((-1, 7, 1))\n",
    "    lstm_predictions=lstm_model.predict(X_Predict_lstm)\n",
    "    lstm_predictionsTest=lstm_model.predict(X_test_lstm)\n",
    "    lstm_predictions = (lstm_predictions > 0.5).astype(int)\n",
    "    lstm_predictionsTest = (lstm_predictionsTest > 0.5).astype(int)\n",
    "    svm_predictions = svm_model.predict(X_Predict)\n",
    "    svm_predictionsTest = svm_model.predict(X_test)\n",
    "    # ایجاد اسکور بر اساس پیش‌بینی‌های SVM\n",
    "    scores = [0 if prediction == 0 else 1 for prediction in svm_predictions]\n",
    "    scoresTest = [0 if prediction2 == 0 else 1 for prediction2 in svm_predictionsTest]\n",
    "    # محاسبه درصد درستی پیش‌بینی‌ها\n",
    "    combined_X = np.column_stack((lstm_predictions, scores))\n",
    "    combined_XTest = np.column_stack((lstm_predictionsTest, scoresTest))\n",
    "   # print(f\" combined_X :{combined_X}\")\n",
    "    #print(f\" combined_XTest :{combined_XTest}\")\n",
    "    combined_predictions = combine_model.predict(combined_X)\n",
    "    combined_predictionsTest = combine_model.predict(combined_XTest)\n",
    "    # accuracy = accuracy_score(y_test, combine_model)\n",
    "\n",
    "    #combined_predictionsTest=lstm_predictionsTest\n",
    "    #combined_predictions=lstm_predictions\n",
    "    print(f\"درصد درستی پیش‌بینی ترکیبی: {accuracy * 100:.2f}%\")\n",
    "    print(f\"combine prediction: {combined_predictions}\")\n",
    "\n",
    "    conf = confusion_matrix(y_test,combined_predictionsTest)\n",
    "    accuracy = CalculatePerAcc(y_test, combined_predictionsTest, conf)\n",
    "\n",
    "    print(f\"confusion Matrix:\\n{conf}\")\n",
    "    print('metrics.classification_report:=\\n',metrics.classification_report(y_test,combined_predictionsTest))\n",
    "    return True,accuracy,combined_predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstTrain On\n",
      "0\n",
      "68474.37\n",
      "Epoch 1/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 90.1076 - val_loss: 37.0830\n",
      "Epoch 2/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.3865 - val_loss: 6.8156\n",
      "Epoch 3/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2971 - val_loss: 8.5126\n",
      "Epoch 4/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3882 - val_loss: 2.9193\n",
      "Epoch 5/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2827 - val_loss: 1.1566\n",
      "Epoch 6/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5343 - val_loss: 0.8612\n",
      "Epoch 7/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8509 - val_loss: 0.7599\n",
      "Epoch 8/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8183 - val_loss: 17.8257\n",
      "Epoch 9/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2562 - val_loss: 2.0754\n",
      "Epoch 10/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8243 - val_loss: 1.7603\n",
      "Epoch 11/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9930 - val_loss: 0.8628\n",
      "Epoch 12/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8579 - val_loss: 33.0468\n",
      "Epoch 13/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4977 - val_loss: 1.8451\n",
      "Epoch 14/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9547 - val_loss: 1.5051\n",
      "Epoch 15/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7934 - val_loss: 1.1018\n",
      "Epoch 16/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7497 - val_loss: 0.9790\n",
      "Epoch 17/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7386 - val_loss: 0.9099\n",
      "Epoch 18/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7743 - val_loss: 0.7105\n",
      "Epoch 19/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7056 - val_loss: 0.6991\n",
      "Epoch 20/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7335 - val_loss: 0.9229\n",
      "Epoch 21/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7354 - val_loss: 1.1440\n",
      "Epoch 22/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1914 - val_loss: 1.1293\n",
      "Epoch 23/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7131 - val_loss: 0.7512\n",
      "Epoch 24/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8232 - val_loss: 0.9280\n",
      "Epoch 25/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7317 - val_loss: 0.7783\n",
      "Epoch 26/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7489 - val_loss: 0.7048\n",
      "Epoch 27/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7167 - val_loss: 0.7836\n",
      "Epoch 28/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6942 - val_loss: 0.6939\n",
      "Epoch 29/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7626 - val_loss: 0.8626\n",
      "Epoch 30/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6981 - val_loss: 1.5629\n",
      "Epoch 31/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7181 - val_loss: 0.7603\n",
      "Epoch 32/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7108 - val_loss: 0.8169\n",
      "Epoch 33/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6959 - val_loss: 0.7731\n",
      "Epoch 34/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7044 - val_loss: 1.2110\n",
      "Epoch 35/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7015 - val_loss: 0.7199\n",
      "Epoch 36/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7087 - val_loss: 0.7724\n",
      "Epoch 37/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7036 - val_loss: 0.7100\n",
      "Epoch 38/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7868 - val_loss: 0.8691\n",
      "Epoch 39/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3111 - val_loss: 0.6961\n",
      "Epoch 40/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1382 - val_loss: 0.7528\n",
      "Epoch 41/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7348 - val_loss: 0.7139\n",
      "Epoch 42/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7807 - val_loss: 0.6916\n",
      "Epoch 43/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7777 - val_loss: 0.6888\n",
      "Epoch 44/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7116 - val_loss: 0.6913\n",
      "Epoch 45/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7039 - val_loss: 0.6943\n",
      "Epoch 46/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7004 - val_loss: 0.6943\n",
      "Epoch 47/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7005 - val_loss: 0.6913\n",
      "Epoch 48/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6946 - val_loss: 0.6931\n",
      "Epoch 49/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7032 - val_loss: 0.6939\n",
      "Epoch 50/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6915 - val_loss: 0.6928\n",
      "Epoch 51/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6966 - val_loss: 0.6913\n",
      "Epoch 52/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6932 - val_loss: 0.6938\n",
      "Epoch 53/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6926 - val_loss: 0.6920\n",
      "Epoch 54/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6915 - val_loss: 0.6939\n",
      "Epoch 55/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6889 - val_loss: 0.6922\n",
      "Epoch 56/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6926 - val_loss: 0.6930\n",
      "Epoch 57/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6902 - val_loss: 0.6925\n",
      "Epoch 58/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6921 - val_loss: 0.6941\n",
      "Epoch 59/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6914 - val_loss: 0.6940\n",
      "Epoch 60/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6934 - val_loss: 0.6936\n",
      "Epoch 61/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6943 - val_loss: 0.6942\n",
      "Epoch 62/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6913 - val_loss: 0.6928\n",
      "Epoch 63/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6896 - val_loss: 0.6930\n",
      "Epoch 64/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6894 - val_loss: 0.6930\n",
      "Epoch 65/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6916 - val_loss: 0.6931\n",
      "Epoch 66/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6887 - val_loss: 0.6932\n",
      "Epoch 67/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6905 - val_loss: 0.6933\n",
      "Epoch 68/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6905 - val_loss: 0.6932\n",
      "Epoch 69/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6846 - val_loss: 0.6932\n",
      "Epoch 70/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6902 - val_loss: 0.6933\n",
      "Epoch 71/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6916 - val_loss: 0.6930\n",
      "Epoch 72/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6950 - val_loss: 0.6935\n",
      "Epoch 73/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6919 - val_loss: 0.6937\n",
      "Epoch 74/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6875 - val_loss: 0.6938\n",
      "Epoch 75/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6900 - val_loss: 0.6937\n",
      "Epoch 76/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6882 - val_loss: 0.6937\n",
      "Epoch 77/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6888 - val_loss: 0.6937\n",
      "Epoch 78/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6932 - val_loss: 0.6938\n",
      "Epoch 79/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6943 - val_loss: 0.6938\n",
      "Epoch 80/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6893 - val_loss: 0.6938\n",
      "Epoch 81/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6874 - val_loss: 0.6937\n",
      "Epoch 82/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6895 - val_loss: 0.6938\n",
      "Epoch 83/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6900 - val_loss: 0.6939\n",
      "Epoch 84/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6902 - val_loss: 0.6939\n",
      "Epoch 85/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6872 - val_loss: 0.6942\n",
      "Epoch 86/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6948 - val_loss: 0.6941\n",
      "Epoch 87/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6891 - val_loss: 0.6940\n",
      "Epoch 88/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6868 - val_loss: 0.6938\n",
      "Epoch 89/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6923 - val_loss: 0.6938\n",
      "Epoch 90/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6942 - val_loss: 0.6938\n",
      "Epoch 91/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6884 - val_loss: 0.6938\n",
      "Epoch 92/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6890 - val_loss: 0.6939\n",
      "Epoch 93/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6948 - val_loss: 0.6941\n",
      "Epoch 94/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6900 - val_loss: 0.6942\n",
      "Epoch 95/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6988 - val_loss: 0.6941\n",
      "Epoch 96/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6893 - val_loss: 0.6941\n",
      "Epoch 97/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6902 - val_loss: 0.6938\n",
      "Epoch 98/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6878 - val_loss: 0.6939\n",
      "Epoch 99/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6855 - val_loss: 0.6944\n",
      "Epoch 100/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6859 - val_loss: 0.6947\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "LSTM Accuracy: 53.19%\n",
      "confusion Matrix:\n",
      "[[14  4]\n",
      " [16 13]]\n",
      "metrics.classification_report:=\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.78      0.58        18\n",
      "           1       0.76      0.45      0.57        29\n",
      "\n",
      "    accuracy                           0.57        47\n",
      "   macro avg       0.62      0.61      0.57        47\n",
      "weighted avg       0.65      0.57      0.57        47\n",
      "\n",
      "recall_score =  0.6130268199233717\n",
      "accuracy:0.6505632040050063\n",
      "C=0.01, gamma=0.01, Accuracy=38.07%\n",
      "C=0.01, gamma=0.001, Accuracy=38.07%\n",
      "C=0.01, gamma=0.005, Accuracy=38.07%\n",
      "C=0.01, gamma=0.5, Accuracy=38.07%\n",
      "C=0.01, gamma=0.1, Accuracy=38.07%\n",
      "C=0.01, gamma=1, Accuracy=38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01, gamma=10, Accuracy=38.07%\n",
      "C=0.01, gamma=100, Accuracy=38.07%\n",
      "C=0.01, gamma=1000, Accuracy=38.07%\n",
      "C=0.01, gamma=0.0001, Accuracy=38.07%\n",
      "C=0.01, gamma=0.9, Accuracy=38.07%\n",
      "C=0.01, gamma=0.8, Accuracy=38.07%\n",
      "C=0.01, gamma=0.7, Accuracy=38.07%\n",
      "C=0.01, gamma=0.6, Accuracy=38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01, gamma=0.4, Accuracy=38.07%\n",
      "C=0.1, gamma=0.01, Accuracy=38.07%\n",
      "C=0.1, gamma=0.001, Accuracy=38.07%\n",
      "C=0.1, gamma=0.005, Accuracy=38.07%\n",
      "C=0.1, gamma=0.5, Accuracy=38.07%\n",
      "C=0.1, gamma=0.1, Accuracy=38.07%\n",
      "C=0.1, gamma=1, Accuracy=38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.1, gamma=10, Accuracy=38.07%\n",
      "C=0.1, gamma=100, Accuracy=38.07%\n",
      "C=0.1, gamma=1000, Accuracy=38.07%\n",
      "C=0.1, gamma=0.0001, Accuracy=38.07%\n",
      "C=0.1, gamma=0.9, Accuracy=38.07%\n",
      "C=0.1, gamma=0.8, Accuracy=38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.1, gamma=0.7, Accuracy=38.07%\n",
      "C=0.1, gamma=0.6, Accuracy=38.07%\n",
      "C=0.1, gamma=0.4, Accuracy=38.07%\n",
      "C=1, gamma=0.01, Accuracy=38.07%\n",
      "C=1, gamma=0.001, Accuracy=38.07%\n",
      "C=1, gamma=0.005, Accuracy=38.07%\n",
      "C=1, gamma=0.5, Accuracy=38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1, gamma=0.1, Accuracy=38.07%\n",
      "C=1, gamma=1, Accuracy=38.07%\n",
      "C=1, gamma=10, Accuracy=38.07%\n",
      "C=1, gamma=100, Accuracy=38.07%\n",
      "C=1, gamma=1000, Accuracy=38.07%\n",
      "C=1, gamma=0.0001, Accuracy=37.56%\n",
      "C=1, gamma=0.9, Accuracy=38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1, gamma=0.8, Accuracy=38.07%\n",
      "C=1, gamma=0.7, Accuracy=38.07%\n",
      "C=1, gamma=0.6, Accuracy=38.07%\n",
      "C=1, gamma=0.4, Accuracy=38.07%\n",
      "C=10, gamma=0.01, Accuracy=38.07%\n",
      "C=10, gamma=0.001, Accuracy=38.07%\n",
      "C=10, gamma=0.005, Accuracy=38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=10, gamma=0.5, Accuracy=38.07%\n",
      "C=10, gamma=0.1, Accuracy=38.07%\n",
      "C=10, gamma=1, Accuracy=38.07%\n",
      "C=10, gamma=10, Accuracy=38.07%\n",
      "C=10, gamma=100, Accuracy=38.07%\n",
      "C=10, gamma=1000, Accuracy=38.07%\n",
      "C=10, gamma=0.0001, Accuracy=37.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=10, gamma=0.9, Accuracy=38.07%\n",
      "C=10, gamma=0.8, Accuracy=38.07%\n",
      "C=10, gamma=0.7, Accuracy=38.07%\n",
      "C=10, gamma=0.6, Accuracy=38.07%\n",
      "C=10, gamma=0.4, Accuracy=38.07%\n",
      "C=100, gamma=0.01, Accuracy=38.07%\n",
      "C=100, gamma=0.001, Accuracy=38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=100, gamma=0.005, Accuracy=38.07%\n",
      "C=100, gamma=0.5, Accuracy=38.07%\n",
      "C=100, gamma=0.1, Accuracy=38.07%\n",
      "C=100, gamma=1, Accuracy=38.07%\n",
      "C=100, gamma=10, Accuracy=38.07%\n",
      "C=100, gamma=100, Accuracy=38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=100, gamma=1000, Accuracy=38.07%\n",
      "C=100, gamma=0.0001, Accuracy=37.56%\n",
      "C=100, gamma=0.9, Accuracy=38.07%\n",
      "C=100, gamma=0.8, Accuracy=38.07%\n",
      "C=100, gamma=0.7, Accuracy=38.07%\n",
      "C=100, gamma=0.6, Accuracy=38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=100, gamma=0.4, Accuracy=38.07%\n",
      "C=1000, gamma=0.01, Accuracy=38.07%\n",
      "C=1000, gamma=0.001, Accuracy=38.07%\n",
      "C=1000, gamma=0.005, Accuracy=38.07%\n",
      "C=1000, gamma=0.5, Accuracy=38.07%\n",
      "C=1000, gamma=0.1, Accuracy=38.07%\n",
      "C=1000, gamma=1, Accuracy=38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1000, gamma=10, Accuracy=38.07%\n",
      "C=1000, gamma=100, Accuracy=38.07%\n",
      "C=1000, gamma=1000, Accuracy=38.07%\n",
      "C=1000, gamma=0.0001, Accuracy=37.56%\n",
      "C=1000, gamma=0.9, Accuracy=38.07%\n",
      "C=1000, gamma=0.8, Accuracy=38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1000, gamma=0.7, Accuracy=38.07%\n",
      "C=1000, gamma=0.6, Accuracy=38.07%\n",
      "C=1000, gamma=0.4, Accuracy=38.07%\n",
      "Best parameters found: {'C': 0.01, 'gamma': 0.01}\n",
      "Best accuracy found: 38.07%\n",
      "metrics.classification_report:=\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.62      1.00      0.76        29\n",
      "\n",
      "    accuracy                           0.62        47\n",
      "   macro avg       0.31      0.50      0.38        47\n",
      "weighted avg       0.38      0.62      0.47        47\n",
      "\n",
      "metrics.classification_report2:=\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       453\n",
      "           1       0.51      1.00      0.68       474\n",
      "\n",
      "    accuracy                           0.51       927\n",
      "   macro avg       0.26      0.50      0.34       927\n",
      "weighted avg       0.26      0.51      0.35       927\n",
      "\n",
      "Final accuracy: 61.70%\n",
      "Confusion matrix:\n",
      "[[ 0 18]\n",
      " [ 0 29]]\n",
      "Confusion matrix2:\n",
      "[[  0 453]\n",
      " [  0 474]]\n",
      "shape YTest:(47,)\n",
      "[1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1]\n",
      "accuracy 47.96%\n",
      "accuracy Combine 55.32%\n",
      "confusion Matrix:\n",
      "[[ 2 16]\n",
      " [ 5 24]]\n",
      "metrics.classification_report:=\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.11      0.16        18\n",
      "           1       0.60      0.83      0.70        29\n",
      "\n",
      "    accuracy                           0.55        47\n",
      "   macro avg       0.44      0.47      0.43        47\n",
      "weighted avg       0.48      0.55      0.49        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def FirstTrain():\n",
    "    global data\n",
    "    global trainTimeStamp\n",
    "    print(\"firstTrain On\")\n",
    "    current_time=get_cyprus_time()\n",
    "\n",
    "    #1. بارگذاری داده ها\n",
    "    new_data=fetch_historical_data(symbol,timeframe,limit)\n",
    "    #اطمینان از اینکه داده های جدید حاوی NaN نباشند\n",
    "    new_data=new_data.ffill()\n",
    "\n",
    "    #2. بررسی تغییرات در داده ها\n",
    "    if not new_data.equals(data):\n",
    "        data=new_data\n",
    "        data['next_close'] = data['close'].shift(-shiftedNumber)\n",
    "        data['target']= (data['next_close']>data['close']).astype(int)\n",
    "        data=add_indicators(data)\n",
    "        # CalculateProfit()     \n",
    "                    \n",
    "    \n",
    "    lstm_model,svm_model,combine_model,accuracy=TrainLstmSVm()\n",
    "    printAcc= round(((accuracy)*100),3)\n",
    "    # if(lstm_model!= None):\n",
    "    #     try:\n",
    "    #         joblib.dump(lstm_model, f'model/lstm_model-{symbol}-{timeframe}-{printAcc}.joblib')\n",
    "    #     except e:\n",
    "    #         print(\"could not Save Lstm Model :{e}\")\n",
    "    # if(svm_model!= None):\n",
    "    #     try:\n",
    "    #         joblib.dump(svm_model, f'model/svm_model{symbol}-{timeframe}-{printAcc}.joblib')\n",
    "    #     except e:\n",
    "    #         print(\"could not Save Svm Model :{e}\")\n",
    "    # if(combine_model!= None):\n",
    "    #     try:\n",
    "    #         joblib.dump(combine_model, f'model/combine_model{symbol}-{timeframe}-{printAcc}.joblib')\n",
    "    #     except e:\n",
    "    #         print(\"could not Save combine Model :{e}\")\n",
    "    trainTimeStamp=datetime.now()\n",
    "    return lstm_model,svm_model,combine_model,accuracy\n",
    "\n",
    "def CalculateProfit():\n",
    "    data['label'] = data.apply(determine_label, axis=1)\n",
    "    data['signal']=3\n",
    "\n",
    "    data['signal'] = data.apply(lambda row: row['target'] if row['label'] == row['target'] else None, axis=1)\n",
    "    data['signal'] = data.apply(lambda row: 2 if row['label'] != row['target'] else row['target'], axis=1)\n",
    "\n",
    "    transactions = []\n",
    "    buy_price = None\n",
    "    open_signal = None\n",
    "\n",
    "    df = data\n",
    "    transactions = []\n",
    "    buy_price = None\n",
    "\n",
    "    open_signal = None\n",
    "    data['transaction']=0\n",
    "    data['marker']=0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        signal = df.at[i, 'signal']\n",
    "        if signal == 0:\n",
    "            if buy_price is None:  # اگر معامله باز نیست، یک معامله باز کنید\n",
    "                buy_price = df.at[i, 'close']\n",
    "                open_signal = 0\n",
    "                data['marker'][i]='B'\n",
    "            elif open_signal == 1:  # اگر معامله باز هست و از 1 به 0 تغییر کرده است\n",
    "                sell_price = df.at[i, 'close']\n",
    "                profit_percent = ((sell_price - buy_price) / buy_price) * 100\n",
    "                transactions.append(profit_percent)\n",
    "                data['transaction'][i]=profit_percent\n",
    "                data['marker'][i]='CB'\n",
    "                buy_price = None  # Reset buy price after the transaction\n",
    "                open_signal = None\n",
    "        elif signal == 1:\n",
    "            if buy_price is None:  # اگر معامله باز نیست، یک معامله باز کنید\n",
    "                buy_price = df.at[i, 'close']\n",
    "                open_signal = 1\n",
    "                data['marker'][i]='B'\n",
    "            elif open_signal == 0:  # اگر معامله باز هست و از 0 به 1 تغییر کرده است\n",
    "                data['marker'][i]='CS'\n",
    "                sell_price = df.at[i, 'close']\n",
    "                profit_percent = ((sell_price - buy_price) / buy_price) * 100\n",
    "                transactions.append(profit_percent)\n",
    "                data['transaction'][i]=profit_percent\n",
    "                buy_price = None  # Reset buy price after the transaction\n",
    "                open_signal = None\n",
    "        elif signal == 2:\n",
    "            if buy_price is not None:  # اگر معامله باز هست و به 2 رسید\n",
    "                sell_price = df.at[i, 'close']\n",
    "                data['marker'][i]='C'\n",
    "                if (open_signal==1):\n",
    "                    profit_percent = ((sell_price - buy_price) / buy_price) * 100\n",
    "                elif (open_signal==0):\n",
    "                    profit_percent = ((sell_price - buy_price) / buy_price) * 100*-1\n",
    "                data['transaction'][i]=profit_percent\n",
    "                data['marker'][i]='C'\n",
    "                transactions.append(profit_percent)\n",
    "                buy_price = None  # Reset buy price after the transaction\n",
    "                open_signal = None\n",
    "\n",
    "\n",
    "    timestamp=data['timestamp'].iloc[-1]\n",
    "    current_time=timestamp.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "    data.to_csv(f\"{symbol}{timeframe}{current_time}.csv\")\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    # if __name__ == '__main__':\n",
    "\n",
    "        # process = multiprocessing.Process(target=DrawChartNew)\n",
    "        # process.start()\n",
    "        # process.join()\n",
    "        # DrawChartNew()\n",
    "\n",
    "\n",
    "    #رسم نمودار\n",
    "    # plt.figure(figsize=(15,10))\n",
    "    #نمودار RSI\n",
    "    # فرض می‌کنیم data یک DataFrame پانداس است و ستون‌های 'timestamp', 'open', 'high', 'low', 'close' را دارد\n",
    "    # data['timestamp'] = pd.to_datetime(data['timestamp'])  # تبدیل ستون timestamp به فرمت datetime\n",
    "    # data['timestamp'] = data['timestamp'].map(mdates.date2num)  # تبدیل به اعداد ترتیبی\n",
    "\n",
    "\n",
    "    # # ohlc = data.loc['timestamp' 'open', 'high', 'low', 'close']\n",
    "    # ohlc = data.loc[:, ['timestamp', 'open', 'high', 'low', 'close']]\n",
    "    # #نمودار سیگنال های خرید و فروش\n",
    "    # fig, ax = plt.subplots() \n",
    "    # candlestick_ohlc(ax, ohlc.values, width=0.6, \n",
    "    #              colorup='green', colordown='red', alpha=0.8) \n",
    "    \n",
    "    # ax.xaxis_date()\n",
    "    # ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    # plt.xticks(rotation=45)\n",
    "    # ax.set_ylabel('Price') \n",
    "    # ax.set_xlabel('Date') \n",
    "    # fig.suptitle(f'Daily Candlestick Chart of {symbol}') \n",
    "    # date_format = mpl_dates.DateFormatter('%d-%m-%Y') \n",
    "    # ax.xaxis.set_major_formatter(date_format) \n",
    "    # fig.autofmt_xdate() \n",
    "    \n",
    "    # fig.tight_layout() \n",
    "    \n",
    "    # # fig.set_dpi(200)\n",
    "    # fig.set_figwidth(640)\n",
    "    # fig.set_figheight(320)\n",
    "    # fig.set_size_inches(12.0, 6.0)\n",
    "    # plt.axis('auto')\n",
    "    # plt.show() \n",
    "\n",
    "\n",
    "    # plt.subplot(1,1,1)\n",
    "    # plt.plot(data['close'],label='Close Price')\n",
    "    # buy_signals=data[data['marker']=='B']\n",
    "    # sell_signals=data[data['marker']=='S']\n",
    "    # close_signals=data[data['marker']=='C']\n",
    "    # close_signalWithSell=data[data['marker']=='CS']\n",
    "    # close_signalWithBuy=data[data['marker']=='CB']\n",
    "    # plt.scatter(buy_signals.index,buy_signals['close'],marker=\"^\",color='g',label='Buy Signal',alpha=1)\n",
    "    # plt.scatter(sell_signals.index,sell_signals['close'],marker=\"v\",color='r',label='Sell Signal',alpha=1)\n",
    "    # plt.scatter(close_signals.index,close_signals['close'],marker=\"_\",color='black',label='Close Signal',alpha=1)\n",
    "    # plt.scatter(close_signalWithSell.index,close_signalWithSell['close'],marker='v',color='r',label='Close With Sell',alpha=1)\n",
    "    # plt.scatter(close_signalWithBuy.index,close_signalWithBuy['close'],marker='^',color='g',label='Close With Buy',alpha=1)\n",
    "    # plt.title('Buy/Sell Signals')\n",
    "    # plt.legend()\n",
    "\n",
    "    # #نمایش نمودار ها\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # print(transactions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lstm_model,svm_model,combine_model,accuracy=FirstTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "68233.84\n",
      "dataCurrent:\n",
      "0\n",
      "\n",
      " dataClose:\n",
      "68233.84\n",
      " x2[-1] :     stochastic         macd     close      volume\n",
      "974   82.752079  1487.252698  68233.84  178.493048\n",
      " lastTest :     stochastic         macd     close      volume\n",
      "974   82.752079  1487.252698  68233.84  178.493048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1]\n",
      "accuracy 38.07%\n",
      "accuracy Combine 61.70%\n",
      "confusion Matrix:\n",
      "[[ 0 18]\n",
      " [ 0 29]]\n",
      "metrics.classification_report:=\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.62      1.00      0.76        29\n",
      "\n",
      "    accuracy                           0.62        47\n",
      "   macro avg       0.31      0.50      0.38        47\n",
      "weighted avg       0.38      0.62      0.47        47\n",
      "\n",
      " Predict Lstm [1]\n",
      " Predict Svm 1\n",
      " Predict Knn 1\n",
      "combined_predictions:1\n",
      "while On\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "68216.43\n",
      "dataCurrent:\n",
      "0\n",
      "\n",
      " dataClose:\n",
      "68216.43\n",
      " x2[-1] :     stochastic         macd     close      volume\n",
      "974    82.51914  1485.863866  68216.43  178.657634\n",
      " lastTest :     stochastic         macd     close      volume\n",
      "974    82.51914  1485.863866  68216.43  178.657634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1]\n",
      "accuracy 38.07%\n",
      "accuracy Combine 61.70%\n",
      "confusion Matrix:\n",
      "[[ 0 18]\n",
      " [ 0 29]]\n",
      "metrics.classification_report:=\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.62      1.00      0.76        29\n",
      "\n",
      "    accuracy                           0.62        47\n",
      "   macro avg       0.31      0.50      0.38        47\n",
      "weighted avg       0.38      0.62      0.47        47\n",
      "\n",
      " Predict Lstm [1]\n",
      " Predict Svm 1\n",
      " Predict Knn 1\n",
      "combined_predictions:1\n",
      "while On\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "68216.43\n",
      "dataCurrent:\n",
      "0\n",
      "\n",
      " dataClose:\n",
      "68216.43\n",
      " x2[-1] :     stochastic         macd     close      volume\n",
      "974    82.51914  1485.863866  68216.43  178.657634\n",
      " lastTest :     stochastic         macd     close      volume\n",
      "974    82.51914  1485.863866  68216.43  178.657634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1]\n",
      "accuracy 38.07%\n",
      "accuracy Combine 61.70%\n",
      "confusion Matrix:\n",
      "[[ 0 18]\n",
      " [ 0 29]]\n",
      "metrics.classification_report:=\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.62      1.00      0.76        29\n",
      "\n",
      "    accuracy                           0.62        47\n",
      "   macro avg       0.31      0.50      0.38        47\n",
      "weighted avg       0.38      0.62      0.47        47\n",
      "\n",
      " Predict Lstm [1]\n",
      " Predict Svm 1\n",
      " Predict Knn 1\n",
      "combined_predictions:1\n",
      "while On\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\vahid\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m current_time\u001b[38;5;241m=\u001b[39mget_cyprus_time()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#1. بارگذاری داده ها\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m new_data\u001b[38;5;241m=\u001b[39m\u001b[43mfetch_historical_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtimeframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#اطمینان از اینکه داده های جدید حاوی NaN نباشند\u001b[39;00m\n\u001b[0;32m     11\u001b[0m new_data\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39mffill()\n",
      "Cell \u001b[1;32mIn[9], line 680\u001b[0m, in \u001b[0;36mfetch_historical_data\u001b[1;34m(symbol, timeframe, limit)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m csv\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     exchange\u001b[38;5;241m=\u001b[39mccxt\u001b[38;5;241m.\u001b[39mbingx()\n\u001b[1;32m--> 680\u001b[0m     ohlcv\u001b[38;5;241m=\u001b[39m\u001b[43mexchange\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_ohlcv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtimeframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m     df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(ohlcv,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    682\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m],unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ccxt\\bingx.py:869\u001b[0m, in \u001b[0;36mbingx.fetch_ohlcv\u001b[1;34m(self, symbol, timeframe, since, limit, params)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_ohlcv\u001b[39m(\u001b[38;5;28mself\u001b[39m, symbol: \u001b[38;5;28mstr\u001b[39m, timeframe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1m\u001b[39m\u001b[38;5;124m'\u001b[39m, since: Int \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, limit: Int \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, params\u001b[38;5;241m=\u001b[39m{}) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mlist\u001b[39m]:\n\u001b[0;32m    853\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;124;03m    fetches historical candlestick data containing the open, high, low, and close price, and the volume of a market\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;124;03m    :see: https://bingx-api.github.io/docs/#/swapV2/market-api.html#K-Line%20Data\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;124;03m    :returns int[][]: A list of candles ordered, open, high, low, close, volume\u001b[39;00m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_markets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     paginate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     paginate, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_option_and_params(params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfetchOHLCV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaginate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ccxt\\base\\exchange.py:1501\u001b[0m, in \u001b[0;36mExchange.load_markets\u001b[1;34m(self, reload, params)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfetchCurrencies\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1500\u001b[0m     currencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_currencies()\n\u001b[1;32m-> 1501\u001b[0m markets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_markets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_markets(markets, currencies)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ccxt\\bingx.py:844\u001b[0m, in \u001b[0;36mbingx.fetch_markets\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isSandbox:\n\u001b[0;32m    843\u001b[0m     requests\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_inverse_swap_markets(params))\n\u001b[1;32m--> 844\u001b[0m     requests\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_spot_markets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# sandbox is swap only\u001b[39;00m\n\u001b[0;32m    845\u001b[0m promises \u001b[38;5;241m=\u001b[39m requests\n\u001b[0;32m    846\u001b[0m linearSwapMarkets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msafe_list(promises, \u001b[38;5;241m0\u001b[39m, [])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ccxt\\bingx.py:646\u001b[0m, in \u001b[0;36mbingx.fetch_spot_markets\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_spot_markets\u001b[39m(\u001b[38;5;28mself\u001b[39m, params):\n\u001b[1;32m--> 646\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspotV1PublicGetCommonSymbols\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;66;03m#    {\u001b[39;00m\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;66;03m#        \"code\": 0,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;66;03m#    }\u001b[39;00m\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msafe_dict(response, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ccxt\\base\\types.py:35\u001b[0m, in \u001b[0;36mEntry.__init__.<locals>.unbound_method\u001b[1;34m(_self, params)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munbound_method\u001b[39m(_self, params\u001b[38;5;241m=\u001b[39m{}):\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_self\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ccxt\\base\\exchange.py:4076\u001b[0m, in \u001b[0;36mExchange.request\u001b[1;34m(self, path, api, method, params, headers, body, config)\u001b[0m\n\u001b[0;32m   4075\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, api: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublic\u001b[39m\u001b[38;5;124m'\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m'\u001b[39m, params\u001b[38;5;241m=\u001b[39m{}, headers: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, body: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, config\u001b[38;5;241m=\u001b[39m{}):\n\u001b[1;32m-> 4076\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ccxt\\base\\exchange.py:4063\u001b[0m, in \u001b[0;36mExchange.fetch2\u001b[1;34m(self, path, api, method, params, headers, body, config)\u001b[0m\n\u001b[0;32m   4061\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, retries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   4062\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4063\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheaders\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4064\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   4065\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, NetworkError):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ccxt\\base\\exchange.py:541\u001b[0m, in \u001b[0;36mExchange.fetch\u001b[1;34m(self, url, method, headers, body)\u001b[0m\n\u001b[0;32m    539\u001b[0m json_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 541\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidateServerSsl\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;66;03m# does not try to detect encoding\u001b[39;00m\n\u001b[0;32m    551\u001b[0m     response\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\http\\client.py:1368\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1367\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1370\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\http\\client.py:317\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\http\\client.py:278\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 278\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1271\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1272\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "\n",
    "\n",
    "        print(\"while On\")\n",
    "        current_time=get_cyprus_time()\n",
    "\n",
    "        #1. بارگذاری داده ها\n",
    "        new_data=fetch_historical_data(symbol,timeframe,limit)\n",
    "        #اطمینان از اینکه داده های جدید حاوی NaN نباشند\n",
    "        new_data=new_data.ffill()\n",
    "       \n",
    "\n",
    "        #2. بررسی تغییرات در داده ها\n",
    "        if not new_data.equals(data):\n",
    "            data=new_data\n",
    "            print(\"dataCurrent:\")\n",
    "            print(data[\"current\"].iloc[-1])\n",
    "            print(\"\\n dataClose:\")\n",
    "            print(data[\"close\"].iloc[-1])\n",
    "\n",
    "            nextTrainTime = add_time_multiple(trainTimeStamp, timeframe,n_Candle_Train)\n",
    "            if(nextTrainTime<datetime.now()):\n",
    "                lstm_model,svm_model,combile_model,accuracy=FirstTrain()\n",
    "            # فرض کنیم data یک DataFrame از pandas باشد و شامل ستون 'close' باشد\n",
    "\n",
    "            # قیمت بسته شدن دو روز بعد\n",
    "            # data['next_close'] = data['close'].shift(-shiftedNumber)\n",
    "\n",
    "            # محاسبه درصد تغییر قیمت دو روز بعد نسبت به قیمت فعلی\n",
    "            # data['percent_change'] = ((data['next_close'] - data['close']) / data['close']) * 100\n",
    "\n",
    "\n",
    "\n",
    "            # اعمال تابع بر روی ستون percent_change برای ایجاد ستون target\n",
    "            # data['target'] = data['percent_change'].apply(determine_target(expectedChange,data['percent_change']))\n",
    "\n",
    "            # حذف ستون‌های موقتی\n",
    "            # data = data.drop(columns=['next_close', 'percent_change'])\n",
    "\n",
    "            # print(data)\n",
    "\n",
    "            # data['next_close'] = data['close'].shift(-1)\n",
    "            data['next_close'] = data['close'].shift(-shiftedNumber)\n",
    "\n",
    "            data['target']= (data['next_close']>data['close']).astype(int)\n",
    "            # data.dropna(inplace=True)\n",
    "\n",
    "            #3.محاسبه شاخص ها\n",
    "            # data['RSI']=calculate_rsi(data['close'])\n",
    "            # data=calculate_rsi(data)\n",
    "            # data['ADX']=calculate_adx(data['high'],data['low'],data['close'])\n",
    "            # data=calculate_adx(data)\n",
    "            # data['plus_di'],data['minus_di']=calculate_di(data)\n",
    "            # data=calculate_di(data)\n",
    "\n",
    "            # data=calculate_mfi(data)\n",
    "            # data=calculate_linear_regression_channel(data)\n",
    "            # data=calculate_macd(data)\n",
    "            data=add_indicators(data)\n",
    "            # data=calculate_supertrend(data)\n",
    "\n",
    "            #4. محاسبه سیگنال های خرید و فروش و بروزرسانی  وضعیت سیکل\n",
    "            # data=calculate_buy_sell_signals(data)\n",
    "\n",
    "            # data=calculate_buy_sell_signalsSuperTrend(data)\n",
    "            # drawChart()\n",
    "\n",
    "            #5. آماده سازی داده ها برای مدل\n",
    "            # X=data[['RSI','ADX','plus_di','minus_di']]\n",
    "            # X=data[['rsi','adx','mfi']]\n",
    "            # y=data['target']\n",
    "\n",
    "\n",
    "            #پاکسازی داده ها از NAN\n",
    "            # X=X.fillna(X.mean())\n",
    "             #جاگزین کردن NaN با میانگین\n",
    "\n",
    "            # ایجاد یک نمونه از MinMaxScaler\n",
    "            # scaler = MinMaxScaler()\n",
    "\n",
    "            # نرمال سازی X\n",
    "            # X = scaler.fit_transform(X)\n",
    "\n",
    "            #K برای یافتن بهترین Cross-validation\n",
    "            # knn=KNeighborsClassifier(metric=lorentzian_distance)\n",
    "            # k_range=range(1,20)\n",
    "            # # cross_val_score=[]\n",
    "            # cv_scores=[]\n",
    "            # for k in k_range:\n",
    "            #     if k%2==0:\n",
    "            #         continue\n",
    "            #     # print(f\" k is:{k}\")\n",
    "            #     knn.n_neighbors=k\n",
    "            #     # scores=cross_val_score(knn,X,y,cv=10,scoring='accuracy')\n",
    "            #     # print(f\"k:{k} and score: {scores}\")\n",
    "            #     # cv_scores.append(scores.mean())\n",
    "            # best_k=k_range[np.argmax(cross_val_score)]\n",
    "\n",
    "            # #آموزش مدل با بهترین KNN\n",
    "            # knn.n_neighbors=best_k\n",
    "            # X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "            # print(X_train)\n",
    "            # knn.fit(X_train,y_train)\n",
    "\n",
    "            #قیمت فعلی بازار است که از داده های اخیر بدست میآید ' latest_price ' فرض کنید\n",
    "            # latest_price=data['current'].iloc[-1]\n",
    "            latest_price=data['close'].iloc[-1]\n",
    "\n",
    "            #7. ارسال آخرین پیش بینی به تلگرام با اضافه کردن قیمت\n",
    "            latest_timestamp=data['timestamp'].iloc[-1]\n",
    "            # latest_prediction=predictions[-1]\n",
    "            #اضافه کردن وضعیت آخرین سیکل به پارامتر های تابع\n",
    "            # latest_cycle_status=data['cycle_status'].iloc[-1]\n",
    "            # all_best_models,accuracy,predictions=Knn()\n",
    "            # all_best_models,accuracy,predictions=LstmSVm()\n",
    "            # all_best_models,accuracy,predictions=PredictCombine(lstm_model,svm_model,combine_model)\n",
    "            all_best_models,accuracy,predictions=Election(lstm_model,svm_model,combine_model)\n",
    "            # predictions, accuracy, predictionNumber = Knn(data, shiftedNumber_range, expectedChange_range, expectedAccuracy)\n",
    "            # all_best_models,accuracy,predictions=MlpClassifier()\n",
    "            #باز کردن سیگنال جدید\n",
    "            if(all_best_models==None or accuracy==None or predictions==None):\n",
    "                continue\n",
    "            elif cycle_status==False and accuracy> expectedAccuracy :\n",
    "\n",
    "                cycle_status=True\n",
    "                lastSignalAction=predictions\n",
    "                # latest_prediction=predictions\n",
    "                signalPrice=latest_price\n",
    "                actionStatus=\"Open\"\n",
    "                profit=0\n",
    "                sendMessage=True\n",
    "                closedMethod=\"\"\n",
    "            #بستن سیگنال جاری با knn\n",
    "            # elif (cycle_status==True and lastSignalAction!=predictions and accuracy> expectedAccuracy)or(CloseSignalWithIndicators(data,1,True,lastSignalAction)):\n",
    "            elif (cycle_status==True and lastSignalAction!=predictions and accuracy> expectedAccuracy):\n",
    "\n",
    "                # if CloseSignalWithIndicators(data,1,True,lastSignalAction):\n",
    "                #     closedMethod=\"Mfi\"\n",
    "                # else:\n",
    "                #     closedMethod=\"KNN\"\n",
    "                closedMethod=\"LStm\"\n",
    "                actionStatus=\"Close\"\n",
    "                cycle_status=False\n",
    "                profit= round(((latest_price-signalPrice)*100)/signalPrice,3)\n",
    "                if lastSignalAction==0:\n",
    "                    profit=profit*-1\n",
    "\n",
    "                lastSignalAction=3\n",
    "                sendMessage=True\n",
    "                # predictions=lastSignalAction\n",
    "\n",
    "            # predictions=all_best_models[0].predict(X_train)\n",
    "            # print(predictions[-1])\n",
    "\n",
    "            # predictions=all_best_models[0].predict(X_train)\n",
    "            # accuracy = accuracy_score(y_test, all_best_models[0].predict(X_test))\n",
    "            # best_k=all_best_models[0].n_neighbors\n",
    "\n",
    "            # best_k=all_best_models.n_neighbors\n",
    "            best_k=1\n",
    "            #6. پیش بینی\n",
    "            # predictions=knn.predict(X_test)\n",
    "            # accuracy=accuracy_score(y_test,predictions)\n",
    "            # confusion_matrix = confusion_matrix(y_test, predictions)\n",
    "            # print(f\"accuracy is:{accuracy}\")\n",
    "            # print(confusion_matrix)\n",
    "\n",
    "\n",
    "            # send_prediction_to_telegram(latest_prediction,latest_timestamp,symbol,accuracy,latest_price,latest_cycle_status,timeframe,best_k)\n",
    "            if sendMessage:\n",
    "                send_prediction_to_telegram(lastSignalAction,latest_timestamp,symbol,accuracy,latest_price,actionStatus,timeframe,best_k,profit,signalPrice,closedMethod)\n",
    "                sendMessage=False\n",
    "            # یک تاخیر کوتاه برای جلوگیری از اتلاف منابغ\n",
    "            time.sleep(0.1)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
